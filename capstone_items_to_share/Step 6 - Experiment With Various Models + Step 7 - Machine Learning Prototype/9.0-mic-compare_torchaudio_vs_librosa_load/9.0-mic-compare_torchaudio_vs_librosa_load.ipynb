{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Imports and configuration](#Imports-and-configuration)\n",
    "* [Data](#Data)\n",
    "* [Loading](#Loading)\n",
    "  * [Trial 1](#Trial-1)\n",
    "  * [Trial 2](#Trial-2)\n",
    "  * [Trial 3](#Trial-3)\n",
    "* [Discussion](#Discussion)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we compare `torchaudio` and `librosa` on how fast they can load a .wav file from my data. Using a slow load method is a potential drag on ease of development that could be avoided. `torchaudio` wins 3 out of 3 trials.\n",
    "\n",
    "## Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "\n",
    "from os import environ\n",
    "from random import seed as random_seed\n",
    "from numpy.random import seed as np_seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "\n",
    "def reset_seeds(seed: int) -> None:\n",
    "    \"\"\"Utility function for resetting random seeds\"\"\"\n",
    "    environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random_seed(seed)\n",
    "    np_seed(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "\n",
    "reset_seeds(SEED := 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extensions\n",
    "%load_ext autotime\n",
    "%load_ext lab_black\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.13 s\n"
     ]
    }
   ],
   "source": [
    "# core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# loading methods\n",
    "import librosa\n",
    "import torchaudio\n",
    "from librosa import load as librosa_load\n",
    "from torchaudio import load as torchaudio_load\n",
    "\n",
    "# utility\n",
    "from gc import collect as gc_collect\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# display outputs w/o print calls\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "# Location of pickled dataframes\n",
    "PICKLED_DF_FOLDER = (\n",
    "    \"../1.0-mic-divide_data_by_duration\"\n",
    ")\n",
    "\n",
    "# The preprocessed data from the Unified Multilingual Dataset of Emotional Human utterances\n",
    "WAV_DIRECTORY = \"../../../unified_multilingual_dataset_of_emotional_human_utterances/data/preprocessed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                          81099\n",
       "unique                                         81099\n",
       "top       00000+aesdd+aesdd.1+f+ang+-1+ell+el-gr.wav\n",
       "freq                                               1\n",
       "Name: file, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "# read medium dataframe\n",
    "files = pd.read_pickle(f\"{PICKLED_DF_FOLDER}/medium.pkl\").file\n",
    "files.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the returned outputs of either load method. We want the outputs to be somewhat similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "sample_files = files.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "00000    [0.0, 0.0007324219, 0.0012207031, 0.002380371,...\n",
       "00001    [0.0020446777, 0.0004272461, -9.1552734e-05, -...\n",
       "00002    [-0.0011291504, -0.0012512207, -0.0014953613, ...\n",
       "00003    [0.0012207031, 0.0010375977, 0.0008239746, 0.0...\n",
       "00004    [0.0, -9.1552734e-05, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "Name: file, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.00073242,  0.0012207 , ..., -0.00030518,\n",
       "       -0.0005188 , -0.00030518], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "66064"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20 ms\n"
     ]
    }
   ],
   "source": [
    "librosa_load_sample = sample_files.apply(\n",
    "    lambda row: librosa_load(path=f\"{WAV_DIRECTORY}/{row}\", sr=None)[0]\n",
    ")\n",
    "librosa_load_sample\n",
    "librosa_load_sample[0]\n",
    "len(librosa_load_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "00000    [tensor(0.), tensor(0.0007), tensor(0.0012), t...\n",
       "00001    [tensor(0.0020), tensor(0.0004), tensor(-9.155...\n",
       "00002    [tensor(-0.0011), tensor(-0.0013), tensor(-0.0...\n",
       "00003    [tensor(0.0012), tensor(0.0010), tensor(0.0008...\n",
       "00004    [tensor(0.), tensor(-9.1553e-05), tensor(0.), ...\n",
       "Name: file, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0007,  0.0012,  ..., -0.0003, -0.0005, -0.0003])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "66064"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "torchaudio_load_sample = sample_files.apply(\n",
    "    lambda row: torchaudio_load(filepath=f\"{WAV_DIRECTORY}/{row}\")[0][0]\n",
    ")\n",
    "torchaudio_load_sample\n",
    "torchaudio_load_sample[0]\n",
    "len(torchaudio_load_sample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resultant `Series` are similar. One holds `numpy` arrays and more precision while the other holds `pytorch` tensors.\n",
    "\n",
    "## Results\n",
    "\n",
    "We will redo some of the previous steps in case there is caching under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.0+cpu\n",
      "0.8.1\n",
      "time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "print(torchaudio.__version__)\n",
    "print(librosa.__version__)\n",
    "del sample_files\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "files = pd.read_pickle(f\"{PICKLED_DF_FOLDER}/medium.pkl\").file.sample(\n",
    "    frac=0.05, random_state=SEED + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.67 s ± 199 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.51 s ± 17.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "time: 41.4 s\n"
     ]
    }
   ],
   "source": [
    "_ = gc_collect()\n",
    "%timeit files.apply(lambda row: librosa_load(path=f\"{WAV_DIRECTORY}/{row}\", sr=None)[0])\n",
    "_ = gc_collect()\n",
    "%timeit files.apply(lambda row: torchaudio_load(filepath=f\"{WAV_DIRECTORY}/{row}\")[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "del files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 149 ms\n"
     ]
    }
   ],
   "source": [
    "files = pd.read_pickle(f\"{PICKLED_DF_FOLDER}/medium.pkl\").file.sample(\n",
    "    frac=0.05, random_state=SEED + 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.59 s ± 170 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.54 s ± 60.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "time: 41 s\n"
     ]
    }
   ],
   "source": [
    "_ = gc_collect()\n",
    "%timeit files.apply(lambda row: librosa_load(path=f\"{WAV_DIRECTORY}/{row}\", sr=None)[0])\n",
    "_ = gc_collect()\n",
    "%timeit files.apply(lambda row: torchaudio_load(filepath=f\"{WAV_DIRECTORY}/{row}\")[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "del files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "files = pd.read_pickle(f\"{PICKLED_DF_FOLDER}/medium.pkl\").file.sample(\n",
    "    frac=0.05, random_state=SEED + 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.54 s ± 132 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.53 s ± 10.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "time: 40.5 s\n"
     ]
    }
   ],
   "source": [
    "_ = gc_collect()\n",
    "%timeit files.apply(lambda row: librosa_load(path=f\"{WAV_DIRECTORY}/{row}\", sr=None)[0])\n",
    "_ = gc_collect()\n",
    "%timeit files.apply(lambda row: torchaudio_load(filepath=f\"{WAV_DIRECTORY}/{row}\")[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "del files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytorch`/`torchaudio` wins 3 out of 3 trials vs `librosa`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5ec24c6db6b01668153f0d7970357104795ba99b94731b011ffeae27cd547f5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
