{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [Intro](#Intro)\n",
    "* [Imports and config](#Imports-and-config)\n",
    "* [Load data](#Load-data)\n",
    "* [Add features](#Add-features)\n",
    "* [Results](#Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, I undersampled the medium set to 800+ samples to evaluate the performance of Random Interval Spectral Ensemble (RISE) from `sktime` and MiniROCKET from `tsai`. Despite sampling <1% of the dataset, both of these took longer to train than I expected. If I recall correctly, RISE took between 2 and 2.5 hours; MiniROCKET was much faster, but still not what I would have expected for a bunch of short audio clips. Moreover, the accuracy scores were only a couple of points higher than a dummy classifier.\n",
    "\n",
    "I also tried Time Series Support Vector Classifier and Learning Shapelets from `tslearn`, but I kept getting out-of-memory errors.\n",
    "\n",
    "I didn't include the notebooks I used for these intial probes since it became clear I would need to adjust my exploration approach to iterate faster. I considered using my Paperspace credits for access to more compute, dimensionality reduction techniques, and PySpark.\n",
    "\n",
    "Perhaps one of the reasons training is so slow is that the main feature is an array of some 80,000+ elements. I might be able to iterate faster if I trained on the MFCCs instead. Accordingly, I am extracting the MFCCs and the mel-and-decibel-scaled spectrograms before I try other models. (Some of the other techniques I'd like to try will use the spectrograms.)\n",
    "\n",
    "For now, we are are only dealing with the short set to avoid memory issues the full dataset entails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "# util\n",
    "from gc import collect as gc_collect\n",
    "from os import remove\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display outputs w/o print calls\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import (\n",
    "    ArrayType,\n",
    "    ByteType,\n",
    "    FloatType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions\n",
    "%load_ext lab_black\n",
    "%load_ext nb_black\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.4 ms\n"
     ]
    }
   ],
   "source": [
    "SEED = 2021\n",
    "\n",
    "# Location of padded data (as pickle)\n",
    "PICKLED_DF_FOLDER = \"../3.0-mic-pad_data_short\"\n",
    "\n",
    "# Location where this notebook will output\n",
    "DATA_OUT_FOLDER = \".\"\n",
    "\n",
    "# The preprocessed data from the Unified Multilingual Dataset of Emotional Human utterances\n",
    "WAV_DIRECTORY = (\n",
    "    \"../../../unified_multilingual_dataset_of_emotional_human_utterances/data/preprocessed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 ms\n"
     ]
    }
   ],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"file\", StringType(), nullable=False),\n",
    "        StructField(\"duration\", StringType(), nullable=False),\n",
    "        StructField(\"source\", StringType(), nullable=False),\n",
    "        StructField(\"speaker_id\", StringType(), nullable=False),\n",
    "        StructField(\"speaker_gender\", StringType(), nullable=False),\n",
    "        StructField(\"emo\", StringType(), nullable=False),\n",
    "        StructField(\"valence\", StringType(), nullable=False),\n",
    "        StructField(\"lang1\", StringType(), nullable=False),\n",
    "        StructField(\"lang2\", StringType(), nullable=False),\n",
    "        StructField(\"neg\", ByteType(), nullable=False),\n",
    "        StructField(\"neu\", ByteType(), nullable=False),\n",
    "        StructField(\"pos\", ByteType(), nullable=False),\n",
    "        StructField(\"length\", StringType(), nullable=False),\n",
    "        StructField(\"padded\", ArrayType(FloatType()), nullable=False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4122"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "gc_collect()\n",
    "short_df = spark.createDataFrame(\n",
    "    pd.read_pickle(f\"{PICKLED_DF_FOLDER}/short_padded.pkl\"),\n",
    "    schema=schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- file: string (nullable = false)\n",
      " |-- duration: string (nullable = false)\n",
      " |-- source: string (nullable = false)\n",
      " |-- speaker_id: string (nullable = false)\n",
      " |-- speaker_gender: string (nullable = false)\n",
      " |-- emo: string (nullable = false)\n",
      " |-- valence: string (nullable = false)\n",
      " |-- lang1: string (nullable = false)\n",
      " |-- lang2: string (nullable = false)\n",
      " |-- neg: byte (nullable = false)\n",
      " |-- neu: byte (nullable = false)\n",
      " |-- pos: byte (nullable = false)\n",
      " |-- length: string (nullable = false)\n",
      " |-- padded: array (nullable = false)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+\n",
      "|                file| duration| source|         speaker_id|speaker_gender|emo|valence|lang1|lang2|neg|neu|pos|length|              padded|\n",
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+\n",
      "|01788+BAUM1+BAUM1...|    0.387|  BAUM1|         BAUM1.s028|             f|hap|      1|  tur|tr-tr|  0|  0|  1| short|[0.0, 0.0, 0.0, 0...|\n",
      "|02024+BAUM2+BAUM2...|    0.417|  BAUM2|         BAUM2.S087|             f|ang|     -1|  eng|   en|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|02196+BAUM2+BAUM2...|    0.417|  BAUM2|         BAUM2.S239|             f|ang|     -1|  tur|tr-tr|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|10245+ekorpus+eko...|    0.485|ekorpus|          ekorpus.0|             f|hap|      1|  est|et-ee|  0|  0|  1| short|[0.0, 0.0, 0.0, 0...|\n",
      "|10512+ekorpus+eko...|    0.471|ekorpus|          ekorpus.0|             f|ang|     -1|  est|et-ee|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|56783+LEGOv2+LEGO...|0.4739375| LEGOv2|LEGOv2.20061122)024|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|56825+LEGOv2+LEGO...|0.4559375| LEGOv2|LEGOv2.20061122)025|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|56836+LEGOv2+LEGO...|0.4059375| LEGOv2|LEGOv2.20061122)028|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57033+LEGOv2+LEGO...|0.3939375| LEGOv2|LEGOv2.20061123)011|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57037+LEGOv2+LEGO...|0.4019375| LEGOv2|LEGOv2.20061123)012|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57042+LEGOv2+LEGO...|0.4159375| LEGOv2|LEGOv2.20061123)012|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57211+LEGOv2+LEGO...|0.4699375| LEGOv2|LEGOv2.20061123)037|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57418+LEGOv2+LEGO...|0.4979375| LEGOv2|LEGOv2.20061123)053|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57479+LEGOv2+LEGO...|0.4979375| LEGOv2|LEGOv2.20061123)058|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57515+LEGOv2+LEGO...|0.4739375| LEGOv2|LEGOv2.20061123)062|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57875+LEGOv2+LEGO...|0.4539375| LEGOv2|LEGOv2.20061124)021|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|58147+LEGOv2+LEGO...|0.3699375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|58148+LEGOv2+LEGO...|0.3479375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|58149+LEGOv2+LEGO...|0.3799375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|58153+LEGOv2+LEGO...|0.3159375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "time: 4.16 s\n"
     ]
    }
   ],
   "source": [
    "short_df.printSchema()\n",
    "gc_collect()\n",
    "short_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+\n",
      "|                file| duration| source|         speaker_id|speaker_gender|emo|valence|lang1|lang2|neg|neu|pos|length|              padded|\n",
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+\n",
      "|01788+BAUM1+BAUM1...|    0.387|  BAUM1|         BAUM1.s028|             f|hap|      1|  tur|tr-tr|  0|  0|  1| short|[0.0, 0.0, 0.0, 0...|\n",
      "|02024+BAUM2+BAUM2...|    0.417|  BAUM2|         BAUM2.S087|             f|ang|     -1|  eng|   en|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|02196+BAUM2+BAUM2...|    0.417|  BAUM2|         BAUM2.S239|             f|ang|     -1|  tur|tr-tr|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|10245+ekorpus+eko...|    0.485|ekorpus|          ekorpus.0|             f|hap|      1|  est|et-ee|  0|  0|  1| short|[0.0, 0.0, 0.0, 0...|\n",
      "|10512+ekorpus+eko...|    0.471|ekorpus|          ekorpus.0|             f|ang|     -1|  est|et-ee|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|56783+LEGOv2+LEGO...|0.4739375| LEGOv2|LEGOv2.20061122)024|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|56825+LEGOv2+LEGO...|0.4559375| LEGOv2|LEGOv2.20061122)025|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|56836+LEGOv2+LEGO...|0.4059375| LEGOv2|LEGOv2.20061122)028|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57033+LEGOv2+LEGO...|0.3939375| LEGOv2|LEGOv2.20061123)011|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57037+LEGOv2+LEGO...|0.4019375| LEGOv2|LEGOv2.20061123)012|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57042+LEGOv2+LEGO...|0.4159375| LEGOv2|LEGOv2.20061123)012|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57211+LEGOv2+LEGO...|0.4699375| LEGOv2|LEGOv2.20061123)037|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57418+LEGOv2+LEGO...|0.4979375| LEGOv2|LEGOv2.20061123)053|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57479+LEGOv2+LEGO...|0.4979375| LEGOv2|LEGOv2.20061123)058|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57515+LEGOv2+LEGO...|0.4739375| LEGOv2|LEGOv2.20061123)062|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|57875+LEGOv2+LEGO...|0.4539375| LEGOv2|LEGOv2.20061124)021|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|58147+LEGOv2+LEGO...|0.3699375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|58148+LEGOv2+LEGO...|0.3479375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|58149+LEGOv2+LEGO...|0.3799375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "|58153+LEGOv2+LEGO...|0.3159375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|\n",
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "gc_collect()\n",
    "short_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll add a column for the Mel Frequency Cepstrum Coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.01 ms\n"
     ]
    }
   ],
   "source": [
    "mfcc = librosa.feature.mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "# Extract MFCCs\n",
    "@pandas_udf(returnType=ArrayType(ArrayType((FloatType()))))\n",
    "def make_mfcc(field: pd.Series) -> pd.Series:\n",
    "    \"\"\"Given a Series of wav arrays, return a Series of extracted Mel Freqeuency Cepstrum Coefficients.\"\"\"\n",
    "    return field.apply(lambda _: mfcc(_, sr=16000).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "short_df = short_df.withColumn(\"mfcc\", make_mfcc(\"padded\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+--------------------+\n",
      "|                file| duration| source|         speaker_id|speaker_gender|emo|valence|lang1|lang2|neg|neu|pos|length|              padded|                mfcc|\n",
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+--------------------+\n",
      "|01788+BAUM1+BAUM1...|    0.387|  BAUM1|         BAUM1.s028|             f|hap|      1|  tur|tr-tr|  0|  0|  1| short|[0.0, 0.0, 0.0, 0...|[[-680.11646, -68...|\n",
      "|02024+BAUM2+BAUM2...|    0.417|  BAUM2|         BAUM2.S087|             f|ang|     -1|  eng|   en|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|[[-573.9075, -419...|\n",
      "|02196+BAUM2+BAUM2...|    0.417|  BAUM2|         BAUM2.S239|             f|ang|     -1|  tur|tr-tr|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|[[-651.4625, -595...|\n",
      "|10245+ekorpus+eko...|    0.485|ekorpus|          ekorpus.0|             f|hap|      1|  est|et-ee|  0|  0|  1| short|[0.0, 0.0, 0.0, 0...|[[-387.688, -308....|\n",
      "|10512+ekorpus+eko...|    0.471|ekorpus|          ekorpus.0|             f|ang|     -1|  est|et-ee|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|[[-499.3053, -235...|\n",
      "|56783+LEGOv2+LEGO...|0.4739375| LEGOv2|LEGOv2.20061122)024|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-507.36606, -43...|\n",
      "|56825+LEGOv2+LEGO...|0.4559375| LEGOv2|LEGOv2.20061122)025|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-479.65567, -35...|\n",
      "|56836+LEGOv2+LEGO...|0.4059375| LEGOv2|LEGOv2.20061122)028|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-540.9684, -540...|\n",
      "|57033+LEGOv2+LEGO...|0.3939375| LEGOv2|LEGOv2.20061123)011|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-575.67035, -57...|\n",
      "|57037+LEGOv2+LEGO...|0.4019375| LEGOv2|LEGOv2.20061123)012|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-548.1814, -548...|\n",
      "|57042+LEGOv2+LEGO...|0.4159375| LEGOv2|LEGOv2.20061123)012|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-552.3849, -552...|\n",
      "|57211+LEGOv2+LEGO...|0.4699375| LEGOv2|LEGOv2.20061123)037|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-504.175, -401....|\n",
      "|57418+LEGOv2+LEGO...|0.4979375| LEGOv2|LEGOv2.20061123)053|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-352.87973, -23...|\n",
      "|57479+LEGOv2+LEGO...|0.4979375| LEGOv2|LEGOv2.20061123)058|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-269.65677, -18...|\n",
      "|57515+LEGOv2+LEGO...|0.4739375| LEGOv2|LEGOv2.20061123)062|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-490.36093, -45...|\n",
      "|57875+LEGOv2+LEGO...|0.4539375| LEGOv2|LEGOv2.20061124)021|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-593.6202, -518...|\n",
      "|58147+LEGOv2+LEGO...|0.3699375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-603.3398, -603...|\n",
      "|58148+LEGOv2+LEGO...|0.3479375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-607.82526, -60...|\n",
      "|58149+LEGOv2+LEGO...|0.3799375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-627.8071, -627...|\n",
      "|58153+LEGOv2+LEGO...|0.3159375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-640.9115, -640...|\n",
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "time: 7.94 s\n"
     ]
    }
   ],
   "source": [
    "gc_collect()\n",
    "short_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also add a column for a decibel-scaled spectrogram on the mel scale. These are represented by arrays also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 96.3 ms\n"
     ]
    }
   ],
   "source": [
    "melspectrogram = librosa.feature.melspectrogram\n",
    "amplitude_to_db = librosa.amplitude_to_db\n",
    "gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(returnType=ArrayType(ArrayType((FloatType()))))\n",
    "def make_melspec_db(field: pd.Series) -> pd.Series:\n",
    "    \"\"\"Given a Series of wav arrays, return a Series of extracted mel-db-scaled spectrogram arrays.\"\"\"\n",
    "    return field.apply(\n",
    "        lambda _: amplitude_to_db(melspectrogram(_, sr=16000), ref=np.max).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 81.8 ms\n"
     ]
    }
   ],
   "source": [
    "short_df = short_df.withColumn(\"melspec_db\", make_melspec_db(short_df.padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+--------------------+--------------------+\n",
      "|                file| duration| source|         speaker_id|speaker_gender|emo|valence|lang1|lang2|neg|neu|pos|length|              padded|                mfcc|          melspec_db|\n",
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+--------------------+--------------------+\n",
      "|01788+BAUM1+BAUM1...|    0.387|  BAUM1|         BAUM1.s028|             f|hap|      1|  tur|tr-tr|  0|  0|  1| short|[0.0, 0.0, 0.0, 0...|[[-680.11646, -68...|[[-80.0, -80.0, -...|\n",
      "|02024+BAUM2+BAUM2...|    0.417|  BAUM2|         BAUM2.S087|             f|ang|     -1|  eng|   en|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|[[-573.9075, -419...|[[-80.0, -80.0, -...|\n",
      "|02196+BAUM2+BAUM2...|    0.417|  BAUM2|         BAUM2.S239|             f|ang|     -1|  tur|tr-tr|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|[[-651.4625, -595...|[[-80.0, -80.0, -...|\n",
      "|10245+ekorpus+eko...|    0.485|ekorpus|          ekorpus.0|             f|hap|      1|  est|et-ee|  0|  0|  1| short|[0.0, 0.0, 0.0, 0...|[[-387.688, -308....|[[-80.0, -80.0, -...|\n",
      "|10512+ekorpus+eko...|    0.471|ekorpus|          ekorpus.0|             f|ang|     -1|  est|et-ee|  1|  0|  0| short|[0.0, 0.0, 0.0, 0...|[[-499.3053, -235...|[[-80.0, -66.6326...|\n",
      "|56783+LEGOv2+LEGO...|0.4739375| LEGOv2|LEGOv2.20061122)024|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-507.36606, -43...|[[-80.0, -80.0, -...|\n",
      "|56825+LEGOv2+LEGO...|0.4559375| LEGOv2|LEGOv2.20061122)025|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-479.65567, -35...|[[-80.0, -80.0, -...|\n",
      "|56836+LEGOv2+LEGO...|0.4059375| LEGOv2|LEGOv2.20061122)028|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-540.9684, -540...|[[-80.0, -80.0, -...|\n",
      "|57033+LEGOv2+LEGO...|0.3939375| LEGOv2|LEGOv2.20061123)011|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-575.67035, -57...|[[-80.0, -80.0, -...|\n",
      "|57037+LEGOv2+LEGO...|0.4019375| LEGOv2|LEGOv2.20061123)012|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-548.1814, -548...|[[-80.0, -80.0, -...|\n",
      "|57042+LEGOv2+LEGO...|0.4159375| LEGOv2|LEGOv2.20061123)012|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-552.3849, -552...|[[-80.0, -80.0, -...|\n",
      "|57211+LEGOv2+LEGO...|0.4699375| LEGOv2|LEGOv2.20061123)037|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-504.175, -401....|[[-80.0, -80.0, -...|\n",
      "|57418+LEGOv2+LEGO...|0.4979375| LEGOv2|LEGOv2.20061123)053|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-352.87973, -23...|[[-80.0, -80.0, -...|\n",
      "|57479+LEGOv2+LEGO...|0.4979375| LEGOv2|LEGOv2.20061123)058|             m|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-269.65677, -18...|[[-80.0, -80.0, -...|\n",
      "|57515+LEGOv2+LEGO...|0.4739375| LEGOv2|LEGOv2.20061123)062|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-490.36093, -45...|[[-80.0, -80.0, -...|\n",
      "|57875+LEGOv2+LEGO...|0.4539375| LEGOv2|LEGOv2.20061124)021|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-593.6202, -518...|[[-80.0, -80.0, -...|\n",
      "|58147+LEGOv2+LEGO...|0.3699375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-603.3398, -603...|[[-80.0, -80.0, -...|\n",
      "|58148+LEGOv2+LEGO...|0.3479375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-607.82526, -60...|[[-80.0, -80.0, -...|\n",
      "|58149+LEGOv2+LEGO...|0.3799375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-627.8071, -627...|[[-80.0, -80.0, -...|\n",
      "|58153+LEGOv2+LEGO...|0.3159375| LEGOv2|LEGOv2.20061125)008|             f|neu|      0|  eng|en-us|  0|  1|  0| short|[0.0, 0.0, 0.0, 0...|[[-640.9115, -640...|[[-80.0, -80.0, -...|\n",
      "+--------------------+---------+-------+-------------------+--------------+---+-------+-----+-----+---+---+---+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "time: 8.33 s\n"
     ]
    }
   ],
   "source": [
    "gc_collect()\n",
    "short_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                mfcc|          melspec_db|\n",
      "+--------------------+--------------------+\n",
      "|[[-680.11646, -68...|[[-80.0, -80.0, -...|\n",
      "|[[-573.9075, -419...|[[-80.0, -80.0, -...|\n",
      "|[[-651.4625, -595...|[[-80.0, -80.0, -...|\n",
      "|[[-387.688, -308....|[[-80.0, -80.0, -...|\n",
      "|[[-499.3053, -235...|[[-80.0, -66.6326...|\n",
      "|[[-507.36606, -43...|[[-80.0, -80.0, -...|\n",
      "|[[-479.65567, -35...|[[-80.0, -80.0, -...|\n",
      "|[[-540.9684, -540...|[[-80.0, -80.0, -...|\n",
      "|[[-575.67035, -57...|[[-80.0, -80.0, -...|\n",
      "|[[-548.1814, -548...|[[-80.0, -80.0, -...|\n",
      "|[[-552.3849, -552...|[[-80.0, -80.0, -...|\n",
      "|[[-504.175, -401....|[[-80.0, -80.0, -...|\n",
      "|[[-352.87973, -23...|[[-80.0, -80.0, -...|\n",
      "|[[-269.65677, -18...|[[-80.0, -80.0, -...|\n",
      "|[[-490.36093, -45...|[[-80.0, -80.0, -...|\n",
      "|[[-593.6202, -518...|[[-80.0, -80.0, -...|\n",
      "|[[-603.3398, -603...|[[-80.0, -80.0, -...|\n",
      "|[[-607.82526, -60...|[[-80.0, -80.0, -...|\n",
      "|[[-627.8071, -627...|[[-80.0, -80.0, -...|\n",
      "|[[-640.9115, -640...|[[-80.0, -80.0, -...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.86 s\n"
     ]
    }
   ],
   "source": [
    "short_df.select(\"mfcc\", \"melspec_db\").show()\n",
    "gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed old parquet tree\n",
      "time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "save_file = f\"{DATA_OUT_FOLDER}/short_plus.parquet\"\n",
    "try:\n",
    "    remove(save_file)\n",
    "    print(\"removed old parquet file\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    rmtree(f\"{save_file}/\")\n",
    "    print(\"removed old parquet tree\")\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "short_df.write.save(save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5ec24c6db6b01668153f0d7970357104795ba99b94731b011ffeae27cd547f5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
