{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [Intro](#Intro)\n",
    "* [Imports and config](#Imports-and-config)\n",
    "* [Load data](#Load-data)\n",
    "  * [Undersample data](#Undersample-data)\n",
    "* [Trim and pad](#Trim-and-pad)\n",
    "* [Train test split](#Train-test-split)\n",
    "* [Minimally Random Convolutional Kernel Transform](#Minimally-Random-Convolutional-Kernel-Transform)\n",
    "* [Results](#Results)\n",
    "* [Discussion](#Discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores the MINImally RandOm Convolutional KErnel Transform (MINIROCKET) method applied to the samples of medium duration without hyperparameter tuning. ROCKET transforms a times series with random convolutional kernels to extract features that are modeled by a linear classifier and MINIROCKET is a scaled-down version of it, training much faster at a marginal cost of classification performance. The model is trained directly on the padded wav arrays.\n",
    "\n",
    "The results are better than a dummy classifier but not by much. Since this method is acclaimed for its speed of training, it may still be worth applying it to the MFCCs or spectrograms as time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions\n",
    "%load_ext lab_black\n",
    "%load_ext nb_black\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "# display outputs w/o print calls\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from gc import collect as gc_collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os             : Windows-10-10.0.22000-SP0\n",
      "python         : 3.8.12\n",
      "tsai           : 0.2.23\n",
      "fastai         : 2.5.2\n",
      "fastcore       : 1.3.26\n",
      "torch          : 1.9.1+cpu\n",
      "n_cpus         : 8\n",
      "device         : cpu\n",
      "time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "from tsai.all import *\n",
    "\n",
    "computer_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.3 ms\n"
     ]
    }
   ],
   "source": [
    "# display outputs w/o print calls\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.6 ms\n"
     ]
    }
   ],
   "source": [
    "SEED = 2021\n",
    "\n",
    "# Location of medium.pkl, which contains the samples of medium duration\n",
    "PICKLED_DF_FOLDER = \"../1.0-mic-divide_data_by_duration\"\n",
    "\n",
    "# Location where this notebook will output\n",
    "DATA_OUT_FOLDER = \".\"\n",
    "\n",
    "# The preprocessed data from the Unified Multilingual Dataset of Emotional Human utterances\n",
    "WAV_DIRECTORY = (\n",
    "    \"../../unified_multilingual_dataset_of_emotional_human_utterances/data/preprocessed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>duration</th>\n",
       "      <th>source</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>speaker_gender</th>\n",
       "      <th>emo</th>\n",
       "      <th>valence</th>\n",
       "      <th>lang1</th>\n",
       "      <th>lang2</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00000</th>\n",
       "      <td>00000+aesdd+aesdd.1+f+ang+-1+ell+el-gr.wav</td>\n",
       "      <td>4.129</td>\n",
       "      <td>aesdd</td>\n",
       "      <td>aesdd.1</td>\n",
       "      <td>f</td>\n",
       "      <td>ang</td>\n",
       "      <td>-1</td>\n",
       "      <td>ell</td>\n",
       "      <td>el-gr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00001</th>\n",
       "      <td>00001+aesdd+aesdd.2+f+ang+-1+ell+el-gr.wav</td>\n",
       "      <td>3.448</td>\n",
       "      <td>aesdd</td>\n",
       "      <td>aesdd.2</td>\n",
       "      <td>f</td>\n",
       "      <td>ang</td>\n",
       "      <td>-1</td>\n",
       "      <td>ell</td>\n",
       "      <td>el-gr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00002</th>\n",
       "      <td>00002+aesdd+aesdd.3+m+ang+-1+ell+el-gr.wav</td>\n",
       "      <td>3.980</td>\n",
       "      <td>aesdd</td>\n",
       "      <td>aesdd.3</td>\n",
       "      <td>m</td>\n",
       "      <td>ang</td>\n",
       "      <td>-1</td>\n",
       "      <td>ell</td>\n",
       "      <td>el-gr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00003</th>\n",
       "      <td>00003+aesdd+aesdd.4+m+ang+-1+ell+el-gr.wav</td>\n",
       "      <td>3.390</td>\n",
       "      <td>aesdd</td>\n",
       "      <td>aesdd.4</td>\n",
       "      <td>m</td>\n",
       "      <td>ang</td>\n",
       "      <td>-1</td>\n",
       "      <td>ell</td>\n",
       "      <td>el-gr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00004</th>\n",
       "      <td>00004+aesdd+aesdd.5+f+ang+-1+ell+el-gr.wav</td>\n",
       "      <td>4.042</td>\n",
       "      <td>aesdd</td>\n",
       "      <td>aesdd.5</td>\n",
       "      <td>f</td>\n",
       "      <td>ang</td>\n",
       "      <td>-1</td>\n",
       "      <td>ell</td>\n",
       "      <td>el-gr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file  duration source speaker_id  \\\n",
       "id                                                                              \n",
       "00000  00000+aesdd+aesdd.1+f+ang+-1+ell+el-gr.wav     4.129  aesdd    aesdd.1   \n",
       "00001  00001+aesdd+aesdd.2+f+ang+-1+ell+el-gr.wav     3.448  aesdd    aesdd.2   \n",
       "00002  00002+aesdd+aesdd.3+m+ang+-1+ell+el-gr.wav     3.980  aesdd    aesdd.3   \n",
       "00003  00003+aesdd+aesdd.4+m+ang+-1+ell+el-gr.wav     3.390  aesdd    aesdd.4   \n",
       "00004  00004+aesdd+aesdd.5+f+ang+-1+ell+el-gr.wav     4.042  aesdd    aesdd.5   \n",
       "\n",
       "      speaker_gender  emo valence lang1  lang2  neg  neu  pos  length  \n",
       "id                                                                     \n",
       "00000              f  ang      -1   ell  el-gr    1    0    0  medium  \n",
       "00001              f  ang      -1   ell  el-gr    1    0    0  medium  \n",
       "00002              m  ang      -1   ell  el-gr    1    0    0  medium  \n",
       "00003              m  ang      -1   ell  el-gr    1    0    0  medium  \n",
       "00004              f  ang      -1   ell  el-gr    1    0    0  medium  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 241 ms\n"
     ]
    }
   ],
   "source": [
    "medium_df = pd.read_pickle(f\"{PICKLED_DF_FOLDER}/medium.pkl\")\n",
    "medium_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.000000    226\n",
       "3.004000    218\n",
       "1.045000    201\n",
       "2.603000    196\n",
       "1.835000    196\n",
       "           ... \n",
       "5.355937      1\n",
       "3.723937      1\n",
       "3.124938      1\n",
       "2.721938      1\n",
       "0.780000      1\n",
       "Name: duration, Length: 6324, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.1 ms\n"
     ]
    }
   ],
   "source": [
    "medium_df.duration.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab 10% of samples from each data source. We only need enough to quickly test out several models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81099"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8109"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>duration</th>\n",
       "      <th>source</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>speaker_gender</th>\n",
       "      <th>emo</th>\n",
       "      <th>valence</th>\n",
       "      <th>lang1</th>\n",
       "      <th>lang2</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01392</th>\n",
       "      <td>01392+BAUM1+BAUM1.s019+f+neu+0+tur+tr-tr.wav</td>\n",
       "      <td>3.821</td>\n",
       "      <td>BAUM1</td>\n",
       "      <td>BAUM1.s019</td>\n",
       "      <td>f</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>tur</td>\n",
       "      <td>tr-tr</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00723</th>\n",
       "      <td>00723+BAUM1+BAUM1.s017+f+dis+-1+tur+tr-tr.wav</td>\n",
       "      <td>3.160</td>\n",
       "      <td>BAUM1</td>\n",
       "      <td>BAUM1.s017</td>\n",
       "      <td>f</td>\n",
       "      <td>dis</td>\n",
       "      <td>-1</td>\n",
       "      <td>tur</td>\n",
       "      <td>tr-tr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00702</th>\n",
       "      <td>00702+BAUM1+BAUM1.s014+m+hap+1+tur+tr-tr.wav</td>\n",
       "      <td>2.755</td>\n",
       "      <td>BAUM1</td>\n",
       "      <td>BAUM1.s014</td>\n",
       "      <td>m</td>\n",
       "      <td>hap</td>\n",
       "      <td>1</td>\n",
       "      <td>tur</td>\n",
       "      <td>tr-tr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01585</th>\n",
       "      <td>01585+BAUM1+BAUM1.s022+f+con+-1+tur+tr-tr.wav</td>\n",
       "      <td>1.795</td>\n",
       "      <td>BAUM1</td>\n",
       "      <td>BAUM1.s022</td>\n",
       "      <td>f</td>\n",
       "      <td>con</td>\n",
       "      <td>-1</td>\n",
       "      <td>tur</td>\n",
       "      <td>tr-tr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00652</th>\n",
       "      <td>00652+BAUM1+BAUM1.s008+m+ang+-1+tur+tr-tr.wav</td>\n",
       "      <td>4.513</td>\n",
       "      <td>BAUM1</td>\n",
       "      <td>BAUM1.s008</td>\n",
       "      <td>m</td>\n",
       "      <td>ang</td>\n",
       "      <td>-1</td>\n",
       "      <td>tur</td>\n",
       "      <td>tr-tr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  duration source  \\\n",
       "id                                                                      \n",
       "01392   01392+BAUM1+BAUM1.s019+f+neu+0+tur+tr-tr.wav     3.821  BAUM1   \n",
       "00723  00723+BAUM1+BAUM1.s017+f+dis+-1+tur+tr-tr.wav     3.160  BAUM1   \n",
       "00702   00702+BAUM1+BAUM1.s014+m+hap+1+tur+tr-tr.wav     2.755  BAUM1   \n",
       "01585  01585+BAUM1+BAUM1.s022+f+con+-1+tur+tr-tr.wav     1.795  BAUM1   \n",
       "00652  00652+BAUM1+BAUM1.s008+m+ang+-1+tur+tr-tr.wav     4.513  BAUM1   \n",
       "\n",
       "       speaker_id speaker_gender  emo valence lang1  lang2  neg  neu  pos  \\\n",
       "id                                                                          \n",
       "01392  BAUM1.s019              f  neu       0   tur  tr-tr    0    1    0   \n",
       "00723  BAUM1.s017              f  dis      -1   tur  tr-tr    1    0    0   \n",
       "00702  BAUM1.s014              m  hap       1   tur  tr-tr    0    0    1   \n",
       "01585  BAUM1.s022              f  con      -1   tur  tr-tr    1    0    0   \n",
       "00652  BAUM1.s008              m  ang      -1   tur  tr-tr    1    0    0   \n",
       "\n",
       "       length  \n",
       "id             \n",
       "01392  medium  \n",
       "00723  medium  \n",
       "00702  medium  \n",
       "01585  medium  \n",
       "00652  medium  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 251 ms\n"
     ]
    }
   ],
   "source": [
    "sample_df = medium_df.groupby(\"source\").sample(frac=0.10, random_state=SEED)\n",
    "len(medium_df)\n",
    "len(sample_df)\n",
    "np.unique(medium_df.source) == np.unique(sample_df.source)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.3 ms\n"
     ]
    }
   ],
   "source": [
    "smaller_sample = sample_df.sample(frac=0.10, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.84 ms\n"
     ]
    }
   ],
   "source": [
    "test_df = smaller_sample.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim and pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some leading silences that are less than 10 ms in duration. In this section, we trim the leading silences and pad the samples up to the maximum duration of the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "# Trim leading silence (more precise than orginally)\n",
    "test_df[\"ragged\"] = test_df.apply(\n",
    "    lambda row: np.trim_zeros(\n",
    "        librosa.load(path=f\"{WAV_DIRECTORY}/{row.file}\", sr=None)[0], trim=\"f\"\n",
    "    ).astype(np.float32),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "max_ragged = test_df.ragged.apply(len).max()\n",
    "\n",
    "# Zero pad with leading silence\n",
    "test_df[\"padded\"] = test_df.apply(\n",
    "    lambda row: np.pad(\n",
    "        row.ragged,\n",
    "        (max_ragged - len(row.ragged), 0),\n",
    "        mode=\"constant\",\n",
    "        constant_values=0,\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      811.000000\n",
       "mean     42168.583231\n",
       "std      16137.424269\n",
       "min       8223.000000\n",
       "25%      31748.500000\n",
       "50%      41600.000000\n",
       "75%      50864.000000\n",
       "max      85665.000000\n",
       "Name: ragged, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "count      811.0\n",
       "mean     85665.0\n",
       "std          0.0\n",
       "min      85665.0\n",
       "25%      85665.0\n",
       "50%      85665.0\n",
       "75%      85665.0\n",
       "max      85665.0\n",
       "Name: padded, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.8 ms\n"
     ]
    }
   ],
   "source": [
    "test_df.ragged.apply(len).describe()\n",
    "test_df.padded.apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid leakage of speaker characteristics, we segregate the speakers of the train split from the test/validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 38.1 ms\n"
     ]
    }
   ],
   "source": [
    "test_speakers = (\n",
    "    pd.DataFrame(np.unique(test_df.speaker_id))\n",
    "    .sample(frac=0.30, random_state=SEED)[0]\n",
    "    .values\n",
    ")\n",
    "\n",
    "X_test = (_ := test_df.loc[test_df.speaker_id.isin(test_speakers)])[[\"padded\"]]\n",
    "y_test = _.neg\n",
    "X_train = (_ := test_df.loc[~test_df.speaker_id.isin(test_speakers)])[[\"padded\"]]\n",
    "y_train = _.neg\n",
    "len(test_df) == len(y_test) + len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.4 ms\n"
     ]
    }
   ],
   "source": [
    "# We will use this to compare the results of training\n",
    "score_to_beat = test_df.neg.value_counts().values[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23346"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 140 ms\n"
     ]
    }
   ],
   "source": [
    "del medium_df\n",
    "del sample_df\n",
    "del smaller_sample\n",
    "del test_df\n",
    "gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimally Random Convolutional Kernel Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MiniRocket was [published in August 2021](https://doi.org/10.1145/3447548.3467231), touting state-of-the-art performance on benchmark time series classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.33 ms\n"
     ]
    }
   ],
   "source": [
    "model = MiniRocketClassifier(random_state=SEED, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 1 of 2) Processing minirocketmultivariate, total= 8.0min\n",
      "[Pipeline] . (step 2 of 2) Processing ridgeclassifiercv, total=   0.7s\n",
      "time: 8min 2s\n"
     ]
    }
   ],
   "source": [
    "fitted_minirocket = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well would a dummy classifier do? (The task is to distinguish between negative and non-negative.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5376078914919852"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.19 ms\n"
     ]
    }
   ],
   "source": [
    "score_to_beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well did MINIROCKET do in comparison?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5655172413793104"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.027909349887325186"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "(minirocket_score := fitted_minirocket.score(X_test, y_test))\n",
    "minirocket_score - score_to_beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I tried using MINIROCKET to classify the audio signal directly. Cursory analysis reveals that it performs slightly better than a dummy classifier would. Although certainly better than a coin flip, the margin is small. The time taken for inference is a little slower than I would have expected (>50% of training time).\n",
    "\n",
    "It may yet be interesting to try MINIROCKET on the spectrograms. Its convolutional nature may be compared to a Convolutional Neural Network, a common architecture for applying computer vision techniques to spectrograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5ec24c6db6b01668153f0d7970357104795ba99b94731b011ffeae27cd547f5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
