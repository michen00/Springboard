{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Imports and configuration](#Imports-and-configuration)\n",
    "* [Metadata and labels](#Metadata-and-labels)\n",
    "  * [emotiontts](#emotiontts)\n",
    "  * [Thorsten_OGV_emotional](#Thorsten_OGV_emotional)\n",
    "  * [x4nth055_SER_custom](#x4nth055_SER_custom)\n",
    "* [Load data](#Load-data)\n",
    "* [Discussion](#Discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Three holdout datasets have been identified. This notebook prepares the labels and metadata for these datasets and then prepares them for extraction of FRILL embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "notebook_begin_time = time()\n",
    "\n",
    "# set random seeds\n",
    "\n",
    "from os import environ\n",
    "from random import seed as random_seed\n",
    "from numpy.random import seed as np_seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "\n",
    "def reset_seeds(seed: int) -> None:\n",
    "    \"\"\"Utility function for resetting random seeds\"\"\"\n",
    "    environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random_seed(seed)\n",
    "    np_seed(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "\n",
    "reset_seeds(SEED := 2021)\n",
    "del environ\n",
    "del random_seed\n",
    "del np_seed\n",
    "del set_seed\n",
    "del reset_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extensions\n",
    "%load_ext autotime\n",
    "%load_ext lab_black\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.44 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# audio processing\n",
    "from pydub import AudioSegment, effects\n",
    "from pydub.silence import detect_leading_silence\n",
    "from torchaudio import load as torchaudio_load\n",
    "\n",
    "# tensorflow & tensorflow_hub\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# utility\n",
    "from pathlib import Path\n",
    "from gc import collect as gc_collect\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# faster\n",
    "import swifter\n",
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "del patch_sklearn\n",
    "\n",
    "# typing\n",
    "from typing import List\n",
    "\n",
    "# display outputs w/o print calls\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "del InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "# Location of audio directories\n",
    "IN_FOLDER = \".\"\n",
    "\n",
    "# Location where this notebook will output\n",
    "OUT_FOLDER = \"./interim\"\n",
    "\n",
    "# Location where the FRILL module is stored locally\n",
    "LOCAL_FRILL = \"../../../FRILL/\"\n",
    "\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## emotiontts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/emotiontts/emotiontts_open_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36 ms\n"
     ]
    }
   ],
   "source": [
    "dataset = \"emotiontts\"\n",
    "emo_codes = (\n",
    "    lambda code: \"neu\"\n",
    "    if code <= 100\n",
    "    else \"hap\"\n",
    "    if code <= 200\n",
    "    else \"ang\"\n",
    "    if code <= 300\n",
    "    else \"sad\"\n",
    ")\n",
    "valence = {\"neu\": \"1\", \"hap\": \"2\", \"ang\": \"0\", \"sad\": \"0\"}  # non-negative coding\n",
    "lang1 = \"kor\"  # ISO 639-3 Korean\n",
    "with open(f\"{dataset}_data_files.tsv\", \"w\") as f:\n",
    "    for file in (Path(\".\") / dataset / \"Emotional\").glob(\"**/*.wav\"):\n",
    "        _ = f.write(\n",
    "            \"\\t\".join(\n",
    "                # dataset+speakerid+gender+emo+val+lang1\n",
    "                [\n",
    "                    f\"{dataset}/Emotional/{file.parents[2].name}/{(speaker := file.parents[1].name)}/wav/{(fname := file.name)}\",\n",
    "                    dataset,\n",
    "                    f\"{dataset}.{speaker}\",\n",
    "                    speaker[-1],\n",
    "                    emo_code := emo_codes(int(fname[5:8])),\n",
    "                    valence[emo_code],\n",
    "                    f\"{lang1}\\n\",\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thorsten_OGV_emotional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zenodo.org/record/5525023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbc0000e16a442cb0d304ed7093f7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 68 ms\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Thorsten_OGV_emotional\"\n",
    "# I deleted some of the unusued folders already\n",
    "# non-negative coding\n",
    "valence = dict.fromkeys([\"ang\", \"dis\", \"sur\"], \"0\")\n",
    "valence[\"neu\"] = \"1\"\n",
    "valence[\"amu\"] = \"2\"\n",
    "lang1 = \"deu\"  # ISO 639-3 German\n",
    "with open(f\"{dataset}_data_files.tsv\", \"w\") as f:\n",
    "    for file in tqdm((Path(\".\") / dataset).glob(\"**/*.wav\")):\n",
    "        _ = f.write(\n",
    "            \"\\t\".join(\n",
    "                [\n",
    "                    # dataset+speakerid+gender+emo+val+lang1\n",
    "                    f\"{dataset}/thorsten-emotional_v02/{(emotion := file.parent.name)}/{(fname := file.name)}\",\n",
    "                    dataset,\n",
    "                    f\"{dataset}.thorsten\",\n",
    "                    \"m\",\n",
    "                    emo_code := emotion[:3],\n",
    "                    valence[emo_code],\n",
    "                    f\"{lang1}\\n\",\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x4nth055_SER_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/x4nth055/emotion-recognition-using-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b583782c35437c80f4318d60745c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40 ms\n"
     ]
    }
   ],
   "source": [
    "dataset = \"x4nth055_SER_custom\"\n",
    "# non-negative coding\n",
    "valence = {\"neu\": \"0\", \"hap\": \"2\"}\n",
    "speaker_gender = {  # I tried my best, but buyer beware: no guarantee of accuracy\n",
    "    \"soumaya\": \"f\",\n",
    "    \"walidlite\": \"m\",\n",
    "    \"zaki\": \"m\",\n",
    "    \"hamed\": \"m\",\n",
    "    \"nadjib\": \"m\",\n",
    "    \"oumaima\": \"f\",\n",
    "    \"rockikz\": \"m\",\n",
    "}\n",
    "lang1 = \"arb\"  # ISO 639-3 Modern Standard Arabic\n",
    "with open(f\"{dataset}_data_files.tsv\", \"w\") as f:\n",
    "    for file in tqdm((Path(\".\") / dataset).glob(\"**/*.wav\")):\n",
    "        # one English sample\n",
    "        if file.stem == \"this-is-good_happy\":\n",
    "            _ = f.write(\n",
    "                \"\\t\".join(\n",
    "                    [\n",
    "                        # dataset+speakerid+gender+emo+val+lang1\n",
    "                        f\"{dataset}/{file.parent.name}/this-is-good_happy.wav\",\n",
    "                        dataset,\n",
    "                        f\"{dataset}.unk\",\n",
    "                        \"u\",\n",
    "                        \"hap\",\n",
    "                        \"2\",\n",
    "                        \"eng\\n\",\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            speaker, emotion = file.stem.split(\"_\")\n",
    "            _ = f.write(\n",
    "                \"\\t\".join(\n",
    "                    [\n",
    "                        # dataset+speakerid+gender+emo+val+lang1\n",
    "                        f\"{dataset}/{file.parent.name}/{file.name}\",\n",
    "                        dataset,\n",
    "                        f\"{dataset}.{(speaker := speaker[:-1])}\",\n",
    "                        speaker_gender[speaker],\n",
    "                        emo_code := emotion[:3],\n",
    "                        valence[emo_code],\n",
    "                        f\"{lang1}\\n\",\n",
    "                    ]\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "def load_file(in_path: str) -> AudioSegment:\n",
    "    \"Load and return an AudioSegment from file.\"\n",
    "    try:\n",
    "        return AudioSegment.from_file(\n",
    "            in_path, format=in_path.rsplit(\".\", maxsplit=1)[-1]\n",
    "        )\n",
    "    except:\n",
    "        try:\n",
    "            return AudioSegment.from_file(in_path)\n",
    "        except:\n",
    "            try:\n",
    "                return AudioSegment.from_file(in_path, format=\"wav\")\n",
    "            except:\n",
    "                try:\n",
    "                    return AudioSegment.from_wav(in_path)\n",
    "                except:\n",
    "                    try:\n",
    "                        return AudioSegment.from_file_using_temporary_files(in_path)\n",
    "                    except:\n",
    "                        try:\n",
    "                            return AudioSegment.from_file(in_path, format=\"aac\")\n",
    "                        except:\n",
    "                            return AudioSegment.from_file(in_path, codec=\"pcm_u16be\")\n",
    "\n",
    "\n",
    "trim_leading_silence: AudioSegment = lambda x: x[\n",
    "    detect_leading_silence(x, silence_threshold=-60.0) :\n",
    "]\n",
    "# detect_leading_silence(_) should return 0 if no leading silence found.\n",
    "# detect_leading_silence() should return len(_) if no end is found (it's all silent) and raise IndexError as a result\n",
    "# default silence_threshold is -50.0 dFBS; lowering it reduces the amount of information lost (in theory)\n",
    "\n",
    "\n",
    "def process_audio(file_: str, line_info: List[str], count: int = 0) -> int:\n",
    "    \"Load, trim, set sample width, set to mono, set frame rate, and write a sound file to OUT_FOLDER.\"\n",
    "    \"Returns 1 if zero duration detected after trim operations, 2 if longer than 1 minute, or 0 after export.\"\n",
    "\n",
    "    # Load\n",
    "    _ = load_file(in_file := f\"{IN_FOLDER}/{file_}\")\n",
    "\n",
    "    # Sample width 16 bits\n",
    "    try:\n",
    "        _ = _.set_sample_width(2)\n",
    "    except:\n",
    "        _ = AudioSegment.from_file_using_temporary_files(in_file).set_sample_width(2)\n",
    "    # Normalize\n",
    "    _ = effects.normalize(_)\n",
    "\n",
    "    # Trim silence\n",
    "    try:\n",
    "        _ = trim_leading_silence(_)\n",
    "        # if not DISCOURSE_CONTEXT[file_.split(\"+\", maxsplit=2)[1]]:\n",
    "        # none of the holdout data were sampled from a discourse context\n",
    "        _ = trim_leading_silence(_.reverse()).reverse()\n",
    "    except IndexError:\n",
    "        print(f\"all silence detected during trim for {file_}\")\n",
    "        return 1\n",
    "    # Filter short and long\n",
    "    if (duration := len(_)) < 200:\n",
    "        print(f\"{file_} is less than 200 ms after trim\")\n",
    "        return 1\n",
    "    if duration > 60000:\n",
    "        print(f\"{file_} exceeds 1 minute in duration\")\n",
    "        return 2\n",
    "    # Set mono 16 kHz\n",
    "    _ = _.set_channels(1)\n",
    "    _ = _.set_frame_rate(16000)\n",
    "\n",
    "    # Write\n",
    "    # count+dataset+speakerid+gender+emo+val+lang1\n",
    "    fname = \"+\".join([f\"{count:05}\"] + line_info)\n",
    "    _.export(\n",
    "        out_f=f\"{OUT_FOLDER}/{fname}.wav\",\n",
    "        format=\"wav\",\n",
    "        codec=\"pcm_s16le\",\n",
    "        bitrate=\"128k\",\n",
    "    )\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_list_of_files() -> List[str]:\n",
    "    \"\"\"Return the files and labels to process by concatenating the TSVs from above\"\"\"\n",
    "    datasets = [\"emotiontts\", \"Thorsten_OGV_emotional\", \"x4nth055_SER_custom\"]\n",
    "    tsv_file = lambda _: f\"{_}_data_files.tsv\"\n",
    "    with open(tsv_file(datasets[0]), \"r\") as f1:\n",
    "        with open(tsv_file(datasets[1]), \"r\") as f2:\n",
    "            with open(tsv_file(datasets[2]), \"r\") as f3:\n",
    "                return f1.readlines() + f2.readlines() + f3.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7fe634ed31d41f38a93f57be82e8185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1957 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no problems in conversion\n",
      "There were 0 files discarded because they were shorter than 200 milliseconds.\n",
      "There were 0 files discarded because duration exceeded 1 minute.\n",
      "There were 0 bad files.\n",
      "time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "bad_files, short_files, long_files = [], [], []\n",
    "\n",
    "count = 0\n",
    "for line in tqdm(get_list_of_files()):\n",
    "    line = line.rstrip().split(\"\\t\")\n",
    "    sample_file = line.pop(0)\n",
    "    try:\n",
    "        if (return_code := process_audio(sample_file, line, count)) == 1:\n",
    "            short_files.append(sample_file)\n",
    "        elif return_code == 2:\n",
    "            long_files.append(sample_file)\n",
    "    except Exception as e:\n",
    "        bad_files.append((sample_file, e))\n",
    "    count += 1\n",
    "else:\n",
    "    print(\"no problems in conversion\")\n",
    "\n",
    "print(\n",
    "    f\"There were {len(short_files)} files discarded because they were shorter than 200 milliseconds.\"\n",
    ")\n",
    "print(\n",
    "    f\"There were {len(long_files)} files discarded because duration exceeded 1 minute.\"\n",
    ")\n",
    "print(f\"There were {len(bad_files)} bad files.\")\n",
    "if bad_files:\n",
    "    print(*bad_files, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5dd1e75bb1b40cdb29dab2f20000cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1957 entries, 0 to 1956\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   id              1957 non-null   uint32  \n",
      " 1   file            1957 non-null   object  \n",
      " 2   source          1957 non-null   category\n",
      " 3   speaker_id      1957 non-null   category\n",
      " 4   speaker_gender  1957 non-null   category\n",
      " 5   lang1           1957 non-null   category\n",
      " 6   emo             1957 non-null   category\n",
      " 7   valence         1957 non-null   int8    \n",
      " 8   neg             1957 non-null   bool    \n",
      " 9   neu             1957 non-null   bool    \n",
      " 10  pos             1957 non-null   bool    \n",
      "dtypes: bool(3), category(5), int8(1), object(1), uint32(1)\n",
      "memory usage: 41.8+ KB\n",
      "time: 126 ms\n"
     ]
    }
   ],
   "source": [
    "labels = {\n",
    "    \"id\": [],\n",
    "    \"file\": [],\n",
    "    \"source\": [],\n",
    "    \"speaker_id\": [],\n",
    "    \"speaker_gender\": [],\n",
    "    \"lang1\": [],\n",
    "    \"emo\": [],\n",
    "    \"valence\": [],\n",
    "    \"neg\": [],\n",
    "    \"neu\": [],\n",
    "    \"pos\": [],\n",
    "}\n",
    "for file in tqdm(Path(\"./interim\").glob(\"*.wav\")):\n",
    "    labels[\"file\"].append(file := file.name)\n",
    "    line = file.rstrip(\".wav\").split(\"+\")\n",
    "    for key in (\n",
    "        \"id\",\n",
    "        \"source\",\n",
    "        \"speaker_id\",\n",
    "        \"speaker_gender\",\n",
    "        \"emo\",\n",
    "        \"valence\",\n",
    "        \"lang1\",\n",
    "    ):\n",
    "        labels[key].append(line.pop(0))\n",
    "    valence = labels[\"valence\"][-1]\n",
    "    labels[\"neg\"].append(valence == \"0\")\n",
    "    labels[\"neu\"].append(valence == \"1\")\n",
    "    labels[\"pos\"].append(valence == \"2\")\n",
    "labels = pd.DataFrame(labels)\n",
    "for categorical in {\"source\", \"speaker_id\", \"speaker_gender\", \"lang1\", \"emo\"}:\n",
    "    # \"category\" is more compact than object dtype\n",
    "    labels[categorical] = labels[categorical].astype(\"category\")\n",
    "labels.valence = labels.valence.astype(np.int8)\n",
    "labels.id = labels.id.astype(np.uint32)  # np.uint32 can store 0 to 4294967295\n",
    "labels.to_feather(\"./holdout_labels.feather\")\n",
    "labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for FRILL extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 135 ms\n"
     ]
    }
   ],
   "source": [
    "df = labels.loc[:, [\"id\", \"file\"]]\n",
    "del labels\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "# Load wav files\n",
    "df[\"ragged\"] = df.file.apply(\n",
    "    lambda row: torchaudio_load(filepath=f\"interim/{row}\")[0][0]\n",
    ")\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the trim operation that also prepares the sequence for FRILL processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1957/1957 [00:00<00:00, 46596.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 170 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df.ragged = df.ragged.swifter.apply(\n",
    "    lambda row: np.expand_dims(np.float32(np.trim_zeros(row.numpy())), axis=0)\n",
    ")\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "# Load FRILL\n",
    "tf.enable_v2_behavior()\n",
    "# module = hub.load(\"https://tfhub.dev/google/nonsemantic-speech-benchmark/frill/1\")\n",
    "module = hub.load(LOCAL_FRILL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1957/1957 [13:49<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15min 3s\n"
     ]
    }
   ],
   "source": [
    "df[\"frill\"] = df.ragged.swifter.apply(lambda _: module(_)[\"embedding\"][0])\n",
    "_ = gc_collect()\n",
    "id = df.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13min 30s\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(df.frill.tolist())\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27min 31s\n"
     ]
    }
   ],
   "source": [
    "df = df.astype(np.float32)\n",
    "df.columns = df.columns.astype(str)\n",
    "df.id = id\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.035624</td>\n",
       "      <td>0.148898</td>\n",
       "      <td>-0.109508</td>\n",
       "      <td>-0.016199</td>\n",
       "      <td>-0.084427</td>\n",
       "      <td>-0.067872</td>\n",
       "      <td>0.174007</td>\n",
       "      <td>-0.033383</td>\n",
       "      <td>-0.017896</td>\n",
       "      <td>-0.024012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153698</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>-0.059062</td>\n",
       "      <td>-0.028037</td>\n",
       "      <td>-0.026091</td>\n",
       "      <td>0.101007</td>\n",
       "      <td>-0.078234</td>\n",
       "      <td>0.112814</td>\n",
       "      <td>0.098813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.103035</td>\n",
       "      <td>0.082011</td>\n",
       "      <td>0.110948</td>\n",
       "      <td>-0.060209</td>\n",
       "      <td>-0.073397</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>-0.020830</td>\n",
       "      <td>0.044276</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>-0.115516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065289</td>\n",
       "      <td>0.075569</td>\n",
       "      <td>-0.089013</td>\n",
       "      <td>-0.161597</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>0.073644</td>\n",
       "      <td>0.058319</td>\n",
       "      <td>0.030772</td>\n",
       "      <td>0.066552</td>\n",
       "      <td>0.088602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.065101</td>\n",
       "      <td>0.038458</td>\n",
       "      <td>-0.029423</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>-0.023002</td>\n",
       "      <td>0.152135</td>\n",
       "      <td>0.053979</td>\n",
       "      <td>-0.039011</td>\n",
       "      <td>0.017791</td>\n",
       "      <td>-0.077413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042246</td>\n",
       "      <td>-0.004320</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>-0.049798</td>\n",
       "      <td>-0.081791</td>\n",
       "      <td>-0.091844</td>\n",
       "      <td>0.164188</td>\n",
       "      <td>0.060485</td>\n",
       "      <td>-0.003494</td>\n",
       "      <td>0.048290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083481</td>\n",
       "      <td>0.138969</td>\n",
       "      <td>-0.030347</td>\n",
       "      <td>0.062699</td>\n",
       "      <td>0.073357</td>\n",
       "      <td>-0.039354</td>\n",
       "      <td>-0.089715</td>\n",
       "      <td>0.113456</td>\n",
       "      <td>0.039636</td>\n",
       "      <td>-0.041954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>-0.181787</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>-0.073927</td>\n",
       "      <td>-0.014689</td>\n",
       "      <td>0.049779</td>\n",
       "      <td>0.044533</td>\n",
       "      <td>-0.063511</td>\n",
       "      <td>0.020476</td>\n",
       "      <td>-0.018876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019141</td>\n",
       "      <td>0.170539</td>\n",
       "      <td>-0.056348</td>\n",
       "      <td>0.032532</td>\n",
       "      <td>-0.089482</td>\n",
       "      <td>0.079703</td>\n",
       "      <td>0.037175</td>\n",
       "      <td>0.046567</td>\n",
       "      <td>-0.053409</td>\n",
       "      <td>-0.061816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078809</td>\n",
       "      <td>-0.044437</td>\n",
       "      <td>-0.086229</td>\n",
       "      <td>0.048539</td>\n",
       "      <td>0.104972</td>\n",
       "      <td>-0.050087</td>\n",
       "      <td>0.052254</td>\n",
       "      <td>0.117372</td>\n",
       "      <td>0.042914</td>\n",
       "      <td>0.049517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.035624  0.148898 -0.109508 -0.016199 -0.084427 -0.067872  0.174007   \n",
       "1 -0.103035  0.082011  0.110948 -0.060209 -0.073397  0.009772 -0.020830   \n",
       "2 -0.065101  0.038458 -0.029423  0.005429 -0.023002  0.152135  0.053979   \n",
       "3  0.083481  0.138969 -0.030347  0.062699  0.073357 -0.039354 -0.089715   \n",
       "4  0.019141  0.170539 -0.056348  0.032532 -0.089482  0.079703  0.037175   \n",
       "\n",
       "          7         8         9  ...      2038      2039      2040      2041  \\\n",
       "0 -0.033383 -0.017896 -0.024012  ... -0.153698  0.041551 -0.003445 -0.059062   \n",
       "1  0.044276  0.046892 -0.115516  ...  0.065289  0.075569 -0.089013 -0.161597   \n",
       "2 -0.039011  0.017791 -0.077413  ... -0.042246 -0.004320 -0.040200 -0.049798   \n",
       "3  0.113456  0.039636 -0.041954  ...  0.022920 -0.181787  0.011134 -0.073927   \n",
       "4  0.046567 -0.053409 -0.061816  ...  0.078809 -0.044437 -0.086229  0.048539   \n",
       "\n",
       "       2042      2043      2044      2045      2046      2047  \n",
       "0 -0.028037 -0.026091  0.101007 -0.078234  0.112814  0.098813  \n",
       "1  0.017945  0.073644  0.058319  0.030772  0.066552  0.088602  \n",
       "2 -0.081791 -0.091844  0.164188  0.060485 -0.003494  0.048290  \n",
       "3 -0.014689  0.049779  0.044533 -0.063511  0.020476 -0.018876  \n",
       "4  0.104972 -0.050087  0.052254  0.117372  0.042914  0.049517  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1957 entries, 0 to 1956\n",
      "Columns: 2048 entries, 0 to 2047\n",
      "dtypes: float32(2048)\n",
      "memory usage: 15.3 MB\n",
      "time: 5.21 s\n"
     ]
    }
   ],
   "source": [
    "df.to_feather(f\"./holdout_FRILL.feather\")\n",
    "_ = pd.read_feather(f\"./holdout_FRILL.feather\")\n",
    "_.head()\n",
    "_.info()\n",
    "del _\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emotiontts is the free sampler part of a larger Korean corpus for text-to-speech synthesis.\n",
    "\n",
    "Thorsten_OGV_emotional consists of utterances from a male German speaker\n",
    "\n",
    "x4nth055_SER_custom are from GitHub user x4nth055's repository for a speech emotion recognition project. While they utilized a lot of the same data as our project, they also uploaded some custom-recorded speech samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed since notebook_begin_time: 3625.6541702747345 s\n",
      "time: 2 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time elapsed since notebook_begin_time: {time() - notebook_begin_time} s\")\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1781be99c106060f3abc0c9b91d3d379f24672894e2158d4b74304109955878"
  },
  "kernelspec": {
   "display_name": "capstone_pyspark_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
