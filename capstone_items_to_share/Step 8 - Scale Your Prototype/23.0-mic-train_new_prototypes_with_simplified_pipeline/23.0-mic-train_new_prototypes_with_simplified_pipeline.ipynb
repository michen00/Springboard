{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Imports and configuration](#Imports-and-configuration)\n",
    "* [Load data](#Load-data)\n",
    "* [Strata](#Strata)\n",
    "* [Hyperparameters](#Hyperparameters)\n",
    "* [Models](#Models)\n",
    "* [Evaluate](#Evaluate)\n",
    "* [Discussion](#Discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "After rounds of feature engineering, visualization & exploration, and tuning various aspects of the classification pipeline, we are about to train new prototypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "notebook_begin_time = time()\n",
    "\n",
    "# set random seeds\n",
    "\n",
    "from os import environ\n",
    "from random import seed as random_seed\n",
    "from numpy.random import seed as np_seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "\n",
    "def reset_seeds(seed: int) -> None:\n",
    "    \"\"\"Utility function for resetting random seeds\"\"\"\n",
    "    environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random_seed(seed)\n",
    "    np_seed(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "\n",
    "reset_seeds(SEED := 2022)\n",
    "del environ\n",
    "del random_seed\n",
    "del np_seed\n",
    "del set_seed\n",
    "del reset_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extensions\n",
    "%load_ext autotime\n",
    "%load_ext lab_black\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.47 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# utility\n",
    "from joblib import dump\n",
    "from gc import collect as gc_collect\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# faster\n",
    "import swifter\n",
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "del patch_sklearn\n",
    "\n",
    "# typing\n",
    "from typing import List, Dict\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "\n",
    "# other sklearn\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import BaggingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, RidgeClassifier\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# display outputs w/o print calls\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "del InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 105 ms\n"
     ]
    }
   ],
   "source": [
    "# Location of FRILL .feather files\n",
    "FRILL_FEATHERS_FOLDER = \"../1.0-mic-extract_FRILL_embeddings\"\n",
    "\n",
    "# Location of pre-final features\n",
    "FEATURES_FOLDER = \".\"\n",
    "\n",
    "# Location where this notebook will output\n",
    "DATA_OUT_FOLDER = \".\"\n",
    "\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 206 ms\n"
     ]
    }
   ],
   "source": [
    "def load_labels() -> pd.DataFrame:\n",
    "    \"\"\"Load just the labels\"\"\"\n",
    "    keep_columns = [\n",
    "        \"id\",\n",
    "        \"source\",\n",
    "        \"speaker_id\",\n",
    "        \"speaker_gender\",\n",
    "        \"emo\",\n",
    "        \"valence\",\n",
    "        \"lang1\",\n",
    "        \"length\",\n",
    "    ]\n",
    "    labels = pd.concat(\n",
    "        (\n",
    "            pd.read_feather(\n",
    "                f\"{FRILL_FEATHERS_FOLDER}/dev_labels.feather\", columns=keep_columns\n",
    "            ),\n",
    "            pd.read_feather(\n",
    "                f\"{FRILL_FEATHERS_FOLDER}/nondev_labels.feather\", columns=keep_columns\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"id\")\n",
    "    return labels\n",
    "\n",
    "\n",
    "def load_data() -> pd.DataFrame:\n",
    "    \"\"\"Loads the FRILL-based features\"\"\"\n",
    "    df = pd.read_feather(\n",
    "        f\"{FEATURES_FOLDER}/scaled_features_ready_for_selection.feather\"\n",
    "    ).set_index(\"id\")\n",
    "    df.columns = df.columns.astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "data = load_data()\n",
    "labels = load_labels().loc[data.index]\n",
    "y_true = labels.valence\n",
    "gnb_features = [\"spherical-LDA1\", \"spherical-LDA2\"]\n",
    "assert all(data.index == labels.index)\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "UInt64Index: 78777 entries, 0 to 87363\n",
      "Data columns (total 51 columns):\n",
      " #   Column                                                                         Non-Null Count  Dtype  \n",
      "---  ------                                                                         --------------  -----  \n",
      " 0   LDA1                                                                           78777 non-null  float64\n",
      " 1   LDA2                                                                           78777 non-null  float64\n",
      " 2   ocLDA_neg                                                                      78777 non-null  float64\n",
      " 3   ocLDA_neu                                                                      78777 non-null  float64\n",
      " 4   ocLDA_pos                                                                      78777 non-null  float64\n",
      " 5   ocSVM_sgdlinear_LDA1                                                           78777 non-null  float64\n",
      " 6   ocSVM_sgdlinear_LDA2                                                           78777 non-null  float64\n",
      " 7   ocSVM_sgdlinear_neg                                                            78777 non-null  float64\n",
      " 8   ocSVM_sgdlinear_neu                                                            78777 non-null  float64\n",
      " 9   ocSVM_sgdlinear_pos                                                            78777 non-null  float64\n",
      " 10  LDA-LOF_neg_30                                                                 78777 non-null  float64\n",
      " 11  LDA-LOF_neu_30                                                                 78777 non-null  float64\n",
      " 12  LDA-LOF_pos_30                                                                 78777 non-null  float64\n",
      " 13  LDA-ocSVM_sgdlinear_neg                                                        78777 non-null  float64\n",
      " 14  LDA-ocSVM_sgdlinear_neu                                                        78777 non-null  float64\n",
      " 15  LDA-ocSVM_sgdlinear_pos                                                        78777 non-null  float64\n",
      " 16  LDA-ocSVM_rbf_neg                                                              78777 non-null  float64\n",
      " 17  LDA-ocSVM_rbf_neu                                                              78777 non-null  float64\n",
      " 18  LDA-ocSVM_rbf_pos                                                              78777 non-null  float64\n",
      " 19  LDA-ocSVM_sigmoid_neg                                                          78777 non-null  float64\n",
      " 20  LDA-ocSVM_sigmoid_neu                                                          78777 non-null  float64\n",
      " 21  LDA-ocSVM_sigmoid_pos                                                          78777 non-null  float64\n",
      " 22  LDA-ocSVM_poly5_neg                                                            78777 non-null  float64\n",
      " 23  LDA-ocSVM_poly5_neu                                                            78777 non-null  float64\n",
      " 24  LDA-ocSVM_poly5_pos                                                            78777 non-null  float64\n",
      " 25  LDA-ocSVM_poly6_neg                                                            78777 non-null  float64\n",
      " 26  LDA-ocSVM_poly6_neu                                                            78777 non-null  float64\n",
      " 27  LDA-ocSVM_poly6_pos                                                            78777 non-null  float64\n",
      " 28  spherical-LDA1                                                                 78777 non-null  float64\n",
      " 29  spherical-LDA2                                                                 78777 non-null  float64\n",
      " 30  spherical-ocLDA_neg                                                            78777 non-null  float64\n",
      " 31  spherical-ocLDA_neu                                                            78777 non-null  float64\n",
      " 32  spherical-ocLDA_pos                                                            78777 non-null  float64\n",
      " 33  theta_LDA1+LDA2                                                                78777 non-null  float64\n",
      " 34  theta_ocLDA_neg+ocLDA_neu+ocLDA_pos                                            78777 non-null  float64\n",
      " 35  phi_ocLDA_neg+ocLDA_neu+ocLDA_pos                                              78777 non-null  float64\n",
      " 36  theta_ocSVM_sgdlinear_LDA1+ocSVM_sgdlinear_LDA2                                78777 non-null  float64\n",
      " 37  theta_ocSVM_sgdlinear_neg+ocSVM_sgdlinear_neu+ocSVM_sgdlinear_pos              78777 non-null  float64\n",
      " 38  phi_ocSVM_sgdlinear_neg+ocSVM_sgdlinear_neu+ocSVM_sgdlinear_pos                78777 non-null  float64\n",
      " 39  theta_LDA-LOF_neg_30+LDA-LOF_neu_30+LDA-LOF_pos_30                             78777 non-null  float64\n",
      " 40  phi_LDA-LOF_neg_30+LDA-LOF_neu_30+LDA-LOF_pos_30                               78777 non-null  float64\n",
      " 41  theta_LDA-ocSVM_sgdlinear_neg+LDA-ocSVM_sgdlinear_neu+LDA-ocSVM_sgdlinear_pos  78777 non-null  float64\n",
      " 42  phi_LDA-ocSVM_sgdlinear_neg+LDA-ocSVM_sgdlinear_neu+LDA-ocSVM_sgdlinear_pos    78777 non-null  float64\n",
      " 43  theta_LDA-ocSVM_rbf_neg+LDA-ocSVM_rbf_neu+LDA-ocSVM_rbf_pos                    78777 non-null  float64\n",
      " 44  phi_LDA-ocSVM_rbf_neg+LDA-ocSVM_rbf_neu+LDA-ocSVM_rbf_pos                      78777 non-null  float64\n",
      " 45  theta_LDA-ocSVM_sigmoid_neg+LDA-ocSVM_sigmoid_neu+LDA-ocSVM_sigmoid_pos        78777 non-null  float64\n",
      " 46  phi_LDA-ocSVM_sigmoid_neg+LDA-ocSVM_sigmoid_neu+LDA-ocSVM_sigmoid_pos          78777 non-null  float64\n",
      " 47  theta_LDA-ocSVM_poly5_neg+LDA-ocSVM_poly5_neu+LDA-ocSVM_poly5_pos              78777 non-null  float64\n",
      " 48  phi_LDA-ocSVM_poly5_neg+LDA-ocSVM_poly5_neu+LDA-ocSVM_poly5_pos                78777 non-null  float64\n",
      " 49  theta_LDA-ocSVM_poly6_neg+LDA-ocSVM_poly6_neu+LDA-ocSVM_poly6_pos              78777 non-null  float64\n",
      " 50  phi_LDA-ocSVM_poly6_neg+LDA-ocSVM_poly6_neu+LDA-ocSVM_poly6_pos                78777 non-null  float64\n",
      "dtypes: float64(51)\n",
      "memory usage: 31.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "UInt64Index: 78777 entries, 0 to 87363\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   source          78777 non-null  category\n",
      " 1   speaker_id      78777 non-null  category\n",
      " 2   speaker_gender  78777 non-null  category\n",
      " 3   emo             78777 non-null  category\n",
      " 4   valence         78777 non-null  int8    \n",
      " 5   lang1           78777 non-null  category\n",
      " 6   length          78777 non-null  category\n",
      "dtypes: category(6), int8(1)\n",
      "memory usage: 1.2 MB\n",
      "time: 34 ms\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 78777/78777 [00:00<00:00, 81157.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.08 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_SPLITS = 8\n",
    "\n",
    "# fields are concatentated for quick permutation omitting non-existent combos\n",
    "strata = labels.loc[\n",
    "    :, [\"source\", \"speaker_gender\", \"emo\", \"valence\", \"lang1\", \"length\"]\n",
    "]\n",
    "strata.valence = strata.valence.astype(str)\n",
    "strata = strata.swifter.apply(\"\".join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 97.9 ms\n"
     ]
    }
   ],
   "source": [
    "# utility function for identifying strata with only i occurences\n",
    "def get_solo(i: int, strata_: pd.Series) -> np.ndarray:\n",
    "    \"\"\"Given a series of stratum memberships, return a shuffled array of strata with only i members.\"\"\"\n",
    "    return np.unique(\n",
    "        strata_.loc[\n",
    "            strata_.isin(\n",
    "                (strata_counts := strata_.value_counts())\n",
    "                .where(strata_counts == i)\n",
    "                .dropna()\n",
    "                .index\n",
    "            )\n",
    "        ]\n",
    "        .sample(frac=1, random_state=SEED)\n",
    "        .values\n",
    "    )\n",
    "\n",
    "\n",
    "# get solos, print stuff\n",
    "def get_onlys(\n",
    "    strata_: pd.Series, print_me: str = \"\", n_splits: int = N_SPLITS\n",
    ") -> List[Dict[int, np.ndarray]]:\n",
    "    \"\"\"Optinally prints something and returns calls of get_solo on strata_ in a list\"\"\"\n",
    "    print(print_me)\n",
    "    solos = []\n",
    "    for i in range(1, n_splits):\n",
    "        solo: np.ndarray = get_solo(i, strata_)\n",
    "        print(f\"only {i}:\", (_ := solo.size))\n",
    "        if _:  # >= 1 strata with only i samples\n",
    "            solos.append({i: solo})\n",
    "    return solos\n",
    "\n",
    "\n",
    "def process_strata(strata: pd.Series, n_splits: int = N_SPLITS) -> pd.Series:\n",
    "    \"\"\"Corrects strata membership column according to n_splits\"\"\"\n",
    "\n",
    "    count = get_onlys_calls = 0\n",
    "\n",
    "    while onlys := get_onlys(\n",
    "        strata,\n",
    "        print_me=f\"merge passes performed: {get_onlys_calls}\",\n",
    "        n_splits=n_splits,\n",
    "    ):\n",
    "        get_onlys_calls += 1\n",
    "        if len(onlys) == 1:\n",
    "            last = onlys[0]\n",
    "            strata_to_merge: np.ndarray = list(last.values())[0]\n",
    "            only_key = list(last.keys())[0]\n",
    "            tuplet_size = n_splits // only_key + (1 if n_splits % only_key else 0)\n",
    "            # perform tuplet merge\n",
    "            interval = len(strata_to_merge) // n_splits\n",
    "            for strata_tuplet in zip(\n",
    "                *[\n",
    "                    strata_to_merge[interval * i : interval * (i + 1)]\n",
    "                    for i in range(tuplet_size)\n",
    "                ]\n",
    "            ):\n",
    "                strata = strata.replace(strata_tuplet, f\"stratum_group_{count}\")\n",
    "                count += 1\n",
    "            remainder = strata_to_merge[tuplet_size * interval :]\n",
    "            if len(remainder) == 1:\n",
    "                # process remainder unmatched\n",
    "                n = n_splits\n",
    "                strata_counts = strata.value_counts()\n",
    "                while not (candidates := strata_counts.loc[strata_counts == n]).size:\n",
    "                    n += 1\n",
    "                strata = strata.replace(\n",
    "                    [remainder[0], candidates.sample(n=1, random_state=SEED).index[0]],\n",
    "                    f\"stratum_group_{count}\",\n",
    "                )\n",
    "                count += 1\n",
    "            else:\n",
    "                # self-pair last\n",
    "                remainder = remainder.tolist()\n",
    "                while len(remainder) >= 2:\n",
    "                    strata = strata.replace(\n",
    "                        (remainder.pop(), remainder.pop()), f\"stratum_group_{count}\"\n",
    "                    )\n",
    "                    count += 1\n",
    "        else:\n",
    "            pop_onlys = lambda _: list(onlys.pop(_).values())[0].tolist()\n",
    "            while len(onlys) >= 2:\n",
    "                # pop the ends\n",
    "                shortside = pop_onlys(0)\n",
    "                longside = pop_onlys(-1)\n",
    "                # merge until one end empty\n",
    "                while shortside and longside:\n",
    "                    strata = strata.replace(\n",
    "                        (shortside.pop(), longside.pop()), f\"stratum_group_{count}\"\n",
    "                    )\n",
    "                    count += 1\n",
    "            if onlys:\n",
    "                # self-pair middle\n",
    "                remainder = pop_onlys(0)\n",
    "                while len(remainder) >= 2:\n",
    "                    strata = strata.replace(\n",
    "                        (remainder.pop(), remainder.pop()), f\"stratum_group_{count}\"\n",
    "                    )\n",
    "                    count += 1\n",
    "    return strata\n",
    "\n",
    "\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge passes performed: 0\n",
      "only 1: 49\n",
      "only 2: 34\n",
      "only 3: 30\n",
      "only 4: 15\n",
      "only 5: 26\n",
      "only 6: 12\n",
      "only 7: 9\n",
      "merge passes performed: 1\n",
      "only 1: 40\n",
      "only 2: 22\n",
      "only 3: 4\n",
      "only 4: 1\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 2\n",
      "only 1: 39\n",
      "only 2: 18\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 5\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 3\n",
      "only 1: 34\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 9\n",
      "only 5: 0\n",
      "only 6: 5\n",
      "only 7: 0\n",
      "merge passes performed: 4\n",
      "only 1: 29\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 1\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 5\n",
      "merge passes performed: 5\n",
      "only 1: 24\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 1\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 6\n",
      "only 1: 23\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 1\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 7\n",
      "only 1: 22\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 0\n",
      "only 6: 1\n",
      "only 7: 0\n",
      "merge passes performed: 8\n",
      "only 1: 21\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 1\n",
      "merge passes performed: 9\n",
      "only 1: 20\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 10\n",
      "only 1: 0\n",
      "only 2: 2\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 11\n",
      "only 1: 0\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 1\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 12\n",
      "only 1: 0\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MELDmneu1engmedium    2905\n",
       "MELDfneu1engmedium    2452\n",
       "esdfneu1engmedium     1750\n",
       "esdfhap2engmedium     1750\n",
       "esdmneu1cmnmedium     1750\n",
       "                      ... \n",
       "stratum_group_2          8\n",
       "stratum_group_18         8\n",
       "stratum_group_46         8\n",
       "stratum_group_33         8\n",
       "stratum_group_45         8\n",
       "Length: 424, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "STRATA = process_strata(strata, n_splits=N_SPLITS)\n",
    "STRATA.value_counts()\n",
    "cross_validator = lambda: StratifiedGroupKFold(\n",
    "    n_splits=N_SPLITS, shuffle=True, random_state=SEED\n",
    ").split(X=data, y=STRATA, groups=labels.speaker_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "var_smoothing = 0.1812436618470557\n",
    "alpha = 100775.25983372086\n",
    "gnb_params = lambda: {\n",
    "    \"base_estimator\": GaussianNB(var_smoothing=var_smoothing),\n",
    "    \"n_estimators\": 50,\n",
    "    \"warm_start\": False,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": SEED,\n",
    "}\n",
    "\n",
    "calibration_params = lambda: {\n",
    "    \"method\": \"isotonic\",\n",
    "    \"cv\": list(cross_validator()),\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "gnb_data = data.loc[:, gnb_features]\n",
    "bagging_gnb = lambda: BaggingClassifier(**gnb_params()).fit(gnb_data, y_true)\n",
    "\n",
    "ridge = lambda: CalibratedClassifierCV(\n",
    "    base_estimator=RidgeClassifier(alpha=alpha, random_state=SEED),\n",
    "    **calibration_params()\n",
    ").fit(data, y_true)\n",
    "\n",
    "voting = lambda: VotingClassifier(\n",
    "    estimators=[\n",
    "        (\n",
    "            \"ridge\",\n",
    "            CalibratedClassifierCV(\n",
    "                base_estimator=RidgeClassifier(alpha=alpha, random_state=SEED),\n",
    "                **calibration_params()\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"gnb\",\n",
    "            Pipeline(\n",
    "                steps=[\n",
    "                    (\n",
    "                        \"select_features\",\n",
    "                        ColumnTransformer(\n",
    "                            transformers=[(\"selector\", \"passthrough\", gnb_features)],\n",
    "                            n_jobs=-1,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (\n",
    "                        \"clf\",\n",
    "                        CalibratedClassifierCV(\n",
    "                            base_estimator=BaggingClassifier(**gnb_params()),\n",
    "                            **calibration_params()\n",
    "                        ),\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    ").fit(data, y_true)\n",
    "\n",
    "stacked_pass = lambda: StackingClassifier(\n",
    "    estimators=[\n",
    "        (\n",
    "            \"ridge\",\n",
    "            RidgeClassifier(alpha=alpha, random_state=SEED),\n",
    "        ),\n",
    "        (\n",
    "            \"gnb\",\n",
    "            Pipeline(\n",
    "                steps=[\n",
    "                    (\n",
    "                        \"select_features\",\n",
    "                        ColumnTransformer(\n",
    "                            transformers=[(\"selector\", \"passthrough\", gnb_features)],\n",
    "                            n_jobs=-1,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (\n",
    "                        \"clf\",\n",
    "                        BaggingClassifier(**gnb_params()),\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    final_estimator=LogisticRegressionCV(\n",
    "        scoring=\"neg_log_loss\",\n",
    "        solver=\"saga\",\n",
    "        max_iter=10000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=SEED,\n",
    "    ),\n",
    "    cv=list(cross_validator()),\n",
    "    n_jobs=-1,\n",
    "    passthrough=True,\n",
    "    verbose=1,\n",
    ").fit(data, y_true)\n",
    "\n",
    "stacked = lambda: StackingClassifier(\n",
    "    estimators=[\n",
    "        (\n",
    "            \"ridge\",\n",
    "            RidgeClassifier(alpha=alpha, random_state=SEED),\n",
    "        ),\n",
    "        (\n",
    "            \"gnb\",\n",
    "            Pipeline(\n",
    "                steps=[\n",
    "                    (\n",
    "                        \"select_features\",\n",
    "                        ColumnTransformer(\n",
    "                            transformers=[(\"selector\", \"passthrough\", gnb_features)],\n",
    "                            n_jobs=-1,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (\n",
    "                        \"clf\",\n",
    "                        BaggingClassifier(**gnb_params()),\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    final_estimator=LogisticRegressionCV(\n",
    "        scoring=\"neg_log_loss\",\n",
    "        solver=\"saga\",\n",
    "        max_iter=10000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=SEED,\n",
    "    ),\n",
    "    cv=list(cross_validator()),\n",
    "    n_jobs=-1,\n",
    "    passthrough=False,\n",
    "    verbose=1,\n",
    ").fit(data, y_true)\n",
    "\n",
    "logreg = lambda: LogisticRegressionCV(\n",
    "    cv=list(cross_validator()),\n",
    "    scoring=\"neg_log_loss\",\n",
    "    solver=\"saga\",\n",
    "    tol=1e-5,\n",
    "    max_iter=100000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    ").fit(data, y_true)\n",
    "\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2h 46min 24s\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"bagging_GNB\": bagging_gnb(),\n",
    "    \"logreg\": logreg(),\n",
    "    \"ridge\": ridge(),\n",
    "    \"voting_gnb_ridge\": voting(),\n",
    "    \"stacked_gnb_ridge\": stacked(),\n",
    "    \"stacked_gnb_ridge_passthrough\": stacked_pass(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba39417ed694f1dbbef1a5ca4fb18c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/bagging_GNB.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/logreg.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/ridge.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/voting_gnb_ridge.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/stacked_gnb_ridge.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/stacked_gnb_ridge_passthrough.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 650 ms\n"
     ]
    }
   ],
   "source": [
    "for model, estimator in tqdm(models.items()):\n",
    "    dump(estimator, f\"{DATA_OUT_FOLDER}/prototypes/{model}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to try again on the holdout data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed since notebook_begin_time: 9996.845714569092 s\n",
      "time: 382 ms\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time elapsed since notebook_begin_time: {time() - notebook_begin_time} s\")\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1781be99c106060f3abc0c9b91d3d379f24672894e2158d4b74304109955878"
  },
  "kernelspec": {
   "display_name": "Python [conda env:capstone_pyspark_38] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
