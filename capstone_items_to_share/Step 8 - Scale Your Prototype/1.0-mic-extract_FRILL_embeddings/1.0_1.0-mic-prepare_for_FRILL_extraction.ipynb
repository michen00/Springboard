{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Imports and configuration](#Imports-and-configuration)\n",
    "* [Load data](#Load-data)\n",
    "* [Preprocess data](#Preprocess-data)\n",
    "* [Development sample](#Development-split)\n",
    "* [Load audio](#Load-audio)\n",
    "* [Save prepared interim data](#Save-prepared-interim-data)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook preprocceses the data in preparation for extraction of FRILL embeddings.\n",
    "\n",
    "I tried several different formats, but pickle was the only one I could get to work with data ready to load and extract.\n",
    "\n",
    "## Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "\n",
    "from os import environ\n",
    "from random import seed as random_seed\n",
    "from numpy.random import seed as np_seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "\n",
    "def reset_seeds(seed: int) -> None:\n",
    "    \"\"\"Utility function for resetting random seeds\"\"\"\n",
    "    environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random_seed(seed)\n",
    "    np_seed(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "\n",
    "reset_seeds(SEED := 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions\n",
    "%load_ext lab_black\n",
    "%load_ext nb_black\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.88 s\n"
     ]
    }
   ],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchaudio import load as torchaudio_load\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# util\n",
    "import swifter\n",
    "from gc import collect as gc_collect\n",
    "from os import remove\n",
    "from shutil import rmtree\n",
    "\n",
    "# display outputs w/o print calls\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.98 ms\n"
     ]
    }
   ],
   "source": [
    "# Location of pickled dataframes\n",
    "PICKLED_DF_FOLDER = \"../../Step 6 - Experiment With Various Models + Step 7 - Machine Learning Prototype/1.0-mic-divide_data_by_duration\"\n",
    "\n",
    "# Location where this notebook will output\n",
    "DATA_OUT_FOLDER = \"D:/interim_data\"\n",
    "\n",
    "# The preprocessed data from the Unified Multilingual Dataset of Emotional Human utterances\n",
    "WAV_DIRECTORY = \"../../../unified_multilingual_dataset_of_emotional_human_utterances/data/preprocessed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "keep_columns = [\n",
    "    \"id\",\n",
    "    \"file\",\n",
    "    \"source\",\n",
    "    \"length\",\n",
    "    \"speaker_id\",\n",
    "    \"speaker_gender\",\n",
    "    \"lang1\",\n",
    "    \"emo\",\n",
    "    \"valence\",\n",
    "    \"neg\",\n",
    "    \"neu\",\n",
    "    \"pos\",\n",
    "]\n",
    "df = pd.read_pickle(f\"{PICKLED_DF_FOLDER}/trimmed_dataframe.pkl\").reset_index()[\n",
    "    keep_columns\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "In this section, the combined dataframe is preprocessed before feature extraction. Three data sources contain non-speech samples, so we recode their language attributes first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eng    59410\n",
       "cmn    17500\n",
       "pes     2876\n",
       "fra     1370\n",
       "tur     1324\n",
       "___     1292\n",
       "est      863\n",
       "ell      603\n",
       "arz      579\n",
       "deu      535\n",
       "urd      400\n",
       "Name: lang1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 39 ms\n"
     ]
    }
   ],
   "source": [
    "df.loc[df.source.isin({\"vivae\", \"LimaCastroScott\", \"MAV\"}), \"lang1\"] = \"___\"\n",
    "df.lang1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 151 ms\n"
     ]
    }
   ],
   "source": [
    "# non-negative integer labels\n",
    "# {0: negative/-1, 1: neutral/0, 2: positive/1}\n",
    "df.valence = np.int8(df.valence) + 1\n",
    "\n",
    "# encode as boolean for compactness\n",
    "for valence in {\"neg\", \"neu\", \"pos\"}:\n",
    "    df[valence] = np.bool_(df[valence])\n",
    "\n",
    "# \"category\" is more compact than object dtype\n",
    "for categorical in {\"source\", \"length\", \"speaker_id\", \"speaker_gender\", \"lang1\", \"emo\"}:\n",
    "    df[categorical] = df[categorical].astype(\"category\")\n",
    "\n",
    "# np.uint32 can store 0 to 4294967295\n",
    "df.id = df.id.astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86752 entries, 0 to 86751\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   id              86752 non-null  uint32  \n",
      " 1   file            86752 non-null  object  \n",
      " 2   source          86752 non-null  category\n",
      " 3   length          86752 non-null  category\n",
      " 4   speaker_id      86752 non-null  category\n",
      " 5   speaker_gender  86752 non-null  category\n",
      " 6   lang1           86752 non-null  category\n",
      " 7   emo             86752 non-null  category\n",
      " 8   valence         86752 non-null  int8    \n",
      " 9   neg             86752 non-null  bool    \n",
      " 10  neu             86752 non-null  bool    \n",
      " 11  pos             86752 non-null  bool    \n",
      "dtypes: bool(3), category(6), int8(1), object(1), uint32(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file</th>\n",
       "      <th>source</th>\n",
       "      <th>length</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>speaker_gender</th>\n",
       "      <th>lang1</th>\n",
       "      <th>emo</th>\n",
       "      <th>valence</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00000+aesdd+aesdd.1+f+ang+-1+ell+el-gr.wav</td>\n",
       "      <td>aesdd</td>\n",
       "      <td>medium</td>\n",
       "      <td>aesdd.1</td>\n",
       "      <td>f</td>\n",
       "      <td>ell</td>\n",
       "      <td>ang</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        file source  length speaker_id  \\\n",
       "0   0  00000+aesdd+aesdd.1+f+ang+-1+ell+el-gr.wav  aesdd  medium    aesdd.1   \n",
       "\n",
       "  speaker_gender lang1  emo  valence   neg    neu    pos  \n",
       "0              f   ell  ang        0  True  False  False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55 ms\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development split\n",
    "\n",
    "In this section, we prepare a separate development set with stratified grouped sampling.\n",
    "\n",
    "First, we set up the strata, making sure each stratum has at least two observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dask Apply: 100%|██████████| 16/16 [00:02<00:00,  5.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MELD.Joeyneu1engmedium              825\n",
       "MELD.Rossneu1engmedium              815\n",
       "MELD.Chandlerneu1engmedium          728\n",
       "MELD.Rachelneu1engmedium            666\n",
       "MELD.Phoebeneu1engmedium            659\n",
       "                                   ... \n",
       "BAUM2.S055sad0engmedium               2\n",
       "stratum_pair_536                      2\n",
       "stratum_pair_194                      2\n",
       "BAUM2.S055sad0englong                 2\n",
       "LEGOv2.20061122)023ang0engmedium      2\n",
       "Length: 4344, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "strata = df[[\"speaker_id\", \"emo\", \"valence\", \"lang1\", \"length\"]]\n",
    "strata.valence = strata.valence.astype(str)\n",
    "strata = strata.swifter.apply(\"\".join, axis=1)\n",
    "\n",
    "\n",
    "def fix_strata_counts(strata: pd.Series) -> None:\n",
    "    \"\"\"Given a Series of strata labels, randomly pair those that only appear once.\"\"\"\n",
    "    solos = (\n",
    "        strata.loc[\n",
    "            strata.isin(\n",
    "                (strata_counts := strata.value_counts()).loc[strata_counts == 1].index\n",
    "            )\n",
    "        ]\n",
    "        .sample(frac=1, random_state=SEED)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    count = 0\n",
    "    n_solos = len(solos)\n",
    "    if n_solos == 1:\n",
    "        pass\n",
    "    else:\n",
    "        for stratum1, stratum2 in zip(solos[: (_ := n_solos // 2)], solos[_:]):\n",
    "            strata.replace((stratum1, stratum2), f\"stratum_pair_{count}\", inplace=True)\n",
    "            count += 1\n",
    "        if n_solos % 2:\n",
    "            strata.replace((solos[n_solos - 1]), f\"stratum_pair_0\", inplace=True)\n",
    "\n",
    "\n",
    "fix_strata_counts(strata)\n",
    "strata.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these strata, we select the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20.4% in dev set'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "# hack for ~25% stratified sample with non-overlapping groups\n",
    "_, presplit = next(\n",
    "    StratifiedGroupKFold(n_splits=2, shuffle=True, random_state=SEED).split(\n",
    "        X=df, y=strata, groups=df.speaker_id\n",
    "    )\n",
    ")\n",
    "\n",
    "X = df.iloc[presplit]\n",
    "y = strata.iloc[presplit]\n",
    "fix_strata_counts(y)\n",
    "\n",
    "_, dev_idx = next(\n",
    "    StratifiedGroupKFold(n_splits=2, shuffle=True, random_state=SEED).split(\n",
    "        X=X, y=y, groups=X.speaker_id\n",
    "    )\n",
    ")\n",
    "nondev_idx = df.drop(df.index[dev_idx]).index\n",
    "\n",
    "f\"{100 * len(dev_idx) / len(df):.1f}% in dev set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "# clean up names\n",
    "del _\n",
    "del fix_strata_counts\n",
    "del PICKLED_DF_FOLDER\n",
    "del presplit\n",
    "del strata\n",
    "del X\n",
    "del y\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16min 18s\n"
     ]
    }
   ],
   "source": [
    "# Load wav files\n",
    "df[\"ragged\"] = df.file.apply(\n",
    "    lambda row: torchaudio_load(filepath=f\"{WAV_DIRECTORY}/{row}\")[0][0]\n",
    ")\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the trim operation that also prepares the sequence for FRILL processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 86752/86752 [00:14<00:00, 5801.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "df.ragged = df.ragged.swifter.apply(\n",
    "    lambda row: np.expand_dims(np.float32(np.trim_zeros(row.numpy())), axis=0)\n",
    ")\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save prepared interim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed old file\n",
      "removed old file\n",
      "time: 2.77 s\n"
     ]
    }
   ],
   "source": [
    "# save it somewhere you have space\n",
    "save_file_dev_labels = f\"{DATA_OUT_FOLDER}/dev_labels.feather\"\n",
    "save_file_nondev_labels = f\"{DATA_OUT_FOLDER}/nondev_labels.feather\"\n",
    "\n",
    "\n",
    "def remove_old(old_file: str) -> None:\n",
    "    \"\"\"Given a file path, remove it if it exists.\"\"\"\n",
    "    try:\n",
    "        remove(old_file)\n",
    "        print(\"removed old file\")\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        rmtree(f\"{old_file}/\")\n",
    "        print(\"removed old tree\")\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "\n",
    "remove_old(save_file_dev_labels)\n",
    "remove_old(save_file_nondev_labels)\n",
    "\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 466 ms\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=\"ragged\").iloc[dev_idx].reset_index().to_feather(save_file_dev_labels)\n",
    "df.drop(columns=\"ragged\").iloc[nondev_idx].reset_index().to_feather(\n",
    "    save_file_nondev_labels\n",
    ")\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32 ms\n"
     ]
    }
   ],
   "source": [
    "def save_prefrill(dev: bool = True, div_size: int = 2500) -> None:\n",
    "    \"\"\"Save the pre-frill features in batches of div_size.\"\"\"\n",
    "    # select index set\n",
    "    idx = dev_idx if dev else nondev_idx\n",
    "    prefix = f\"{DATA_OUT_FOLDER}/{'dev' if dev else 'nondev_prefrill/nondev'}_prefrill_\"\n",
    "    len_idx = len(idx)\n",
    "    for i in range(last_i := len_idx // div_size):  # each \"fold\"\n",
    "        remove_old(save_path := f\"{prefix}{i}.pkl\")\n",
    "        _ = gc_collect()\n",
    "        # save a pickle\n",
    "        df[[\"id\", \"ragged\"]].iloc[idx[(_ := i * div_size) : _ + div_size]].reset_index(\n",
    "            drop=True\n",
    "        ).to_pickle(save_path)\n",
    "    if len_idx % div_size:  # leftovers\n",
    "        remove_old(save_path := f\"{prefix}{last_i}.pkl\")\n",
    "        df[[\"id\", \"ragged\"]].iloc[idx[(last_i * div_size) :]].reset_index(\n",
    "            drop=True\n",
    "        ).to_pickle(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save and preview the pickles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed old file\n",
      "removed old file\n",
      "removed old file\n",
      "removed old file\n",
      "removed old file\n",
      "removed old file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ragged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0007324219, 0.0012207031, 0.002380371, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             ragged\n",
       "0   0  [[0.0007324219, 0.0012207031, 0.002380371, 0.0..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 56.1 s\n"
     ]
    }
   ],
   "source": [
    "save_prefrill(dev=True)\n",
    "pd.read_pickle(f\"{DATA_OUT_FOLDER}/dev_prefrill_0.pkl\").head(1)\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed old file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ragged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0020446777, 0.0004272461, -9.1552734e-05, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             ragged\n",
       "0   1  [[0.0020446777, 0.0004272461, -9.1552734e-05, ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 17s\n"
     ]
    }
   ],
   "source": [
    "# reduced div_size so I may potentially continue extracting FRILL features on the side while I worked actively with dev features\n",
    "save_prefrill(dev=False, div_size=500)\n",
    "pd.read_pickle(f\"{DATA_OUT_FOLDER}/nondev_prefrill/nondev_prefrill_0.pkl\").head(1)\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^top](#Contents)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1781be99c106060f3abc0c9b91d3d379f24672894e2158d4b74304109955878"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('capstone_pyspark_38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
