{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Imports and configuration](#Imports-and-configuration)\n",
    "* [Load data](#Load-data)\n",
    "* [Strata](#Strata)\n",
    "* [Hyperparameters](#Hyperparameters)\n",
    "* [Models](#Models)\n",
    "* [Evaluate](#Evaluate)\n",
    "* [Discussion](#Discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "After rounds of feature engineering, visualization & exploration, and tuning various aspects of the classification pipeline, we are about to create new prototypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "notebook_begin_time = time()\n",
    "\n",
    "# set random seeds\n",
    "\n",
    "from os import environ\n",
    "from random import seed as random_seed\n",
    "from numpy.random import seed as np_seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "\n",
    "def reset_seeds(seed: int) -> None:\n",
    "    \"\"\"Utility function for resetting random seeds\"\"\"\n",
    "    environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random_seed(seed)\n",
    "    np_seed(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "\n",
    "reset_seeds(SEED := 2022)\n",
    "del environ\n",
    "del random_seed\n",
    "del np_seed\n",
    "del set_seed\n",
    "del reset_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extensions\n",
    "%load_ext autotime\n",
    "%load_ext lab_black\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.61 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# utility\n",
    "from joblib import dump\n",
    "from gc import collect as gc_collect\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# faster\n",
    "import swifter\n",
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "del patch_sklearn\n",
    "\n",
    "# typing\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "# other sklearn\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import BaggingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    "    LogisticRegressionCV,\n",
    "    RidgeClassifier,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# display outputs w/o print calls\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "del InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 116 ms\n"
     ]
    }
   ],
   "source": [
    "# Location of FRILL .feather files\n",
    "FRILL_FEATHERS_FOLDER = \"../1.0-mic-extract_FRILL_embeddings\"\n",
    "\n",
    "# Location of pre-final features\n",
    "FEATURES_FOLDER = \".\"\n",
    "\n",
    "# Location where this notebook will output\n",
    "DATA_OUT_FOLDER = \".\"\n",
    "\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 185 ms\n"
     ]
    }
   ],
   "source": [
    "def load_labels() -> pd.DataFrame:\n",
    "    \"\"\"Load just the labels\"\"\"\n",
    "    keep_columns = [\n",
    "        \"id\",\n",
    "        \"source\",\n",
    "        \"speaker_id\",\n",
    "        \"speaker_gender\",\n",
    "        \"emo\",\n",
    "        \"valence\",\n",
    "        \"lang1\",\n",
    "        \"length\",\n",
    "    ]\n",
    "    labels = pd.concat(\n",
    "        (\n",
    "            pd.read_feather(\n",
    "                f\"{FRILL_FEATHERS_FOLDER}/dev_labels.feather\", columns=keep_columns\n",
    "            ),\n",
    "            pd.read_feather(\n",
    "                f\"{FRILL_FEATHERS_FOLDER}/nondev_labels.feather\", columns=keep_columns\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"id\")\n",
    "    return labels\n",
    "\n",
    "\n",
    "def load_data() -> pd.DataFrame:\n",
    "    \"\"\"Loads the FRILL-based features\"\"\"\n",
    "    df = pd.read_feather(\n",
    "        f\"{FEATURES_FOLDER}/scaled_features_ready_for_selection.feather\"\n",
    "    ).set_index(\"id\")\n",
    "    df.columns = df.columns.astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "data = load_data()\n",
    "labels = load_labels().loc[data.index]\n",
    "y_true = labels.valence\n",
    "gnb_features = [\"spherical-LDA1\", \"spherical-LDA2\"]\n",
    "assert all(data.index == labels.index)\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "UInt64Index: 85740 entries, 0 to 87363\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   LDA1                     85740 non-null  float64\n",
      " 1   LDA2                     85740 non-null  float64\n",
      " 2   ocSVM_sgdlinear_neg      85740 non-null  float64\n",
      " 3   ocSVM_sgdlinear_neu      85740 non-null  float64\n",
      " 4   ocSVM_sgdlinear_pos      85740 non-null  float64\n",
      " 5   LDA-LOF_neg_20           85740 non-null  float64\n",
      " 6   LDA-LOF_neu_20           85740 non-null  float64\n",
      " 7   LDA-LOF_pos_20           85740 non-null  float64\n",
      " 8   LDA-ocSVM_rbf_neg        85740 non-null  float64\n",
      " 9   LDA-ocSVM_rbf_neu        85740 non-null  float64\n",
      " 10  LDA-ocSVM_rbf_pos        85740 non-null  float64\n",
      " 11  LDA-ocSVM_sgdlinear_neg  85740 non-null  float64\n",
      " 12  LDA-ocSVM_sgdlinear_neu  85740 non-null  float64\n",
      " 13  LDA-ocSVM_sgdlinear_pos  85740 non-null  float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 9.8 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "UInt64Index: 85740 entries, 0 to 87363\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   source          85740 non-null  category\n",
      " 1   speaker_id      85740 non-null  category\n",
      " 2   speaker_gender  85740 non-null  category\n",
      " 3   emo             85740 non-null  category\n",
      " 4   valence         85740 non-null  int8    \n",
      " 5   lang1           85740 non-null  category\n",
      " 6   length          85740 non-null  category\n",
      "dtypes: category(6), int8(1)\n",
      "memory usage: 1.4 MB\n",
      "time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dask Apply: 100%|██████████| 16/16 [00:02<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.61 s\n"
     ]
    }
   ],
   "source": [
    "N_SPLITS = 8\n",
    "\n",
    "# fields are concatentated for quick permutation omitting non-existent combos\n",
    "strata = labels.loc[\n",
    "    :, [\"source\", \"speaker_gender\", \"emo\", \"valence\", \"lang1\", \"length\"]\n",
    "]\n",
    "strata.valence = strata.valence.astype(str)\n",
    "strata = strata.swifter.apply(\"\".join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "# utility function for identifying strata with only i occurences\n",
    "def get_solo(i: int, strata_: pd.Series) -> np.ndarray:\n",
    "    \"\"\"Given a series of stratum memberships, return a shuffled array of strata with only i members.\"\"\"\n",
    "    return np.unique(\n",
    "        strata_.loc[\n",
    "            strata_.isin(\n",
    "                (strata_counts := strata_.value_counts())\n",
    "                .where(strata_counts == i)\n",
    "                .dropna()\n",
    "                .index\n",
    "            )\n",
    "        ]\n",
    "        .sample(frac=1, random_state=SEED)\n",
    "        .values\n",
    "    )\n",
    "\n",
    "\n",
    "# get solos, print stuff\n",
    "def get_onlys(\n",
    "    strata_: pd.Series, print_me: str = \"\", n_splits: int = N_SPLITS\n",
    ") -> List[Dict[int, np.ndarray]]:\n",
    "    \"\"\"Optinally prints something and returns calls of get_solo on strata_ in a list\"\"\"\n",
    "    print(print_me)\n",
    "    solos = []\n",
    "    for i in range(1, n_splits):\n",
    "        solo: np.ndarray = get_solo(i, strata_)\n",
    "        print(f\"only {i}:\", (_ := solo.size))\n",
    "        if _:  # >= 1 strata with only i samples\n",
    "            solos.append({i: solo})\n",
    "    return solos\n",
    "\n",
    "\n",
    "def process_strata(strata: pd.Series, n_splits: int = N_SPLITS) -> pd.Series:\n",
    "    \"\"\"Corrects strata membership column according to n_splits\"\"\"\n",
    "\n",
    "    count = get_onlys_calls = 0\n",
    "\n",
    "    while onlys := get_onlys(\n",
    "        strata,\n",
    "        print_me=f\"merge passes performed: {get_onlys_calls}\",\n",
    "        n_splits=n_splits,\n",
    "    ):\n",
    "        get_onlys_calls += 1\n",
    "        if len(onlys) == 1:\n",
    "            last = onlys[0]\n",
    "            strata_to_merge: np.ndarray = list(last.values())[0]\n",
    "            only_key = list(last.keys())[0]\n",
    "            tuplet_size = n_splits // only_key + (1 if n_splits % only_key else 0)\n",
    "            # perform tuplet merge\n",
    "            interval = len(strata_to_merge) // n_splits\n",
    "            for strata_tuplet in zip(\n",
    "                *[\n",
    "                    strata_to_merge[interval * i : interval * (i + 1)]\n",
    "                    for i in range(tuplet_size)\n",
    "                ]\n",
    "            ):\n",
    "                strata = strata.replace(strata_tuplet, f\"stratum_group_{count}\")\n",
    "                count += 1\n",
    "            remainder = strata_to_merge[tuplet_size * interval :]\n",
    "            if len(remainder) == 1:\n",
    "                # process remainder unmatched\n",
    "                n = n_splits\n",
    "                strata_counts = strata.value_counts()\n",
    "                while not (candidates := strata_counts.loc[strata_counts == n]).size:\n",
    "                    n += 1\n",
    "                strata = strata.replace(\n",
    "                    [remainder[0], candidates.sample(n=1, random_state=SEED).index[0]],\n",
    "                    f\"stratum_group_{count}\",\n",
    "                )\n",
    "                count += 1\n",
    "            else:\n",
    "                # self-pair last\n",
    "                remainder = remainder.tolist()\n",
    "                while len(remainder) >= 2:\n",
    "                    strata = strata.replace(\n",
    "                        (remainder.pop(), remainder.pop()), f\"stratum_group_{count}\"\n",
    "                    )\n",
    "                    count += 1\n",
    "        else:\n",
    "            pop_onlys = lambda _: list(onlys.pop(_).values())[0].tolist()\n",
    "            while len(onlys) >= 2:\n",
    "                # pop the ends\n",
    "                shortside = pop_onlys(0)\n",
    "                longside = pop_onlys(-1)\n",
    "                # merge until one end empty\n",
    "                while shortside and longside:\n",
    "                    strata = strata.replace(\n",
    "                        (shortside.pop(), longside.pop()), f\"stratum_group_{count}\"\n",
    "                    )\n",
    "                    count += 1\n",
    "            if onlys:\n",
    "                # self-pair middle\n",
    "                remainder = pop_onlys(0)\n",
    "                while len(remainder) >= 2:\n",
    "                    strata = strata.replace(\n",
    "                        (remainder.pop(), remainder.pop()), f\"stratum_group_{count}\"\n",
    "                    )\n",
    "                    count += 1\n",
    "    return strata\n",
    "\n",
    "\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge passes performed: 0\n",
      "only 1: 52\n",
      "only 2: 37\n",
      "only 3: 31\n",
      "only 4: 17\n",
      "only 5: 27\n",
      "only 6: 13\n",
      "only 7: 9\n",
      "merge passes performed: 1\n",
      "only 1: 43\n",
      "only 2: 24\n",
      "only 3: 4\n",
      "only 4: 1\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 2\n",
      "only 1: 42\n",
      "only 2: 20\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 5\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 3\n",
      "only 1: 37\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 10\n",
      "only 5: 0\n",
      "only 6: 5\n",
      "only 7: 0\n",
      "merge passes performed: 4\n",
      "only 1: 32\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 5\n",
      "merge passes performed: 5\n",
      "only 1: 27\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 6\n",
      "only 1: 1\n",
      "only 2: 1\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 7\n",
      "only 1: 0\n",
      "only 2: 0\n",
      "only 3: 1\n",
      "only 4: 0\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 0\n",
      "merge passes performed: 8\n",
      "only 1: 0\n",
      "only 2: 0\n",
      "only 3: 0\n",
      "only 4: 0\n",
      "only 5: 0\n",
      "only 6: 0\n",
      "only 7: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MELDmneu1engmedium     2905\n",
       "MELDfneu1engmedium     2452\n",
       "esdmang0cmnmedium      1750\n",
       "esdmneu1cmnmedium      1750\n",
       "esdmhap2cmnmedium      1750\n",
       "                       ... \n",
       "stratum_group_84          8\n",
       "stratum_group_38          8\n",
       "stratum_group_94          8\n",
       "BAUM2fcon0engmedium       8\n",
       "stratum_group_90          8\n",
       "Length: 449, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.87 s\n"
     ]
    }
   ],
   "source": [
    "STRATA = process_strata(strata, n_splits=N_SPLITS)\n",
    "STRATA.value_counts()\n",
    "cross_validator = lambda: StratifiedGroupKFold(\n",
    "    n_splits=N_SPLITS, shuffle=True, random_state=SEED\n",
    ").split(X=data, y=STRATA, groups=labels.speaker_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 97.2 ms\n"
     ]
    }
   ],
   "source": [
    "var_smoothing = 0.026743984632167556\n",
    "alpha = 97874.43620365807\n",
    "logreg_C = 0.011514411442955409\n",
    "\n",
    "ridge_params = lambda: {\n",
    "    \"alpha\": alpha,\n",
    "    \"random_state\": SEED,\n",
    "}\n",
    "\n",
    "\n",
    "def logreg_params(logreg_C: Union[None, float] = 10.0) -> Dict[str, Union[float, str]]:\n",
    "    \"\"\"return logistic regression paramaters\"\"\"\n",
    "    logreg_params = {\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"tol\": 1e-5,\n",
    "        \"max_iter\": 100000,\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": SEED + 1,\n",
    "    }\n",
    "    if logreg_C:\n",
    "        logreg_params[\"C\"] = logreg_C\n",
    "    return logreg_params\n",
    "\n",
    "\n",
    "gnb_params = lambda: {\n",
    "    \"base_estimator\": GaussianNB(var_smoothing=var_smoothing),\n",
    "    \"n_estimators\": 50,\n",
    "    \"warm_start\": False,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": SEED + 2,\n",
    "}\n",
    "\n",
    "calibration_params = lambda: {\n",
    "    \"method\": \"isotonic\",\n",
    "    \"cv\": list(cross_validator()),\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "bagging_gnb = lambda: BaggingClassifier(**gnb_params()).fit(data, y_true)\n",
    "\n",
    "ridge = lambda: CalibratedClassifierCV(\n",
    "    base_estimator=RidgeClassifier(**ridge_params()), **calibration_params()\n",
    ").fit(data, y_true)\n",
    "\n",
    "voting_gnb_ridge = lambda: VotingClassifier(\n",
    "    estimators=[\n",
    "        (\n",
    "            \"gnb\",\n",
    "            CalibratedClassifierCV(\n",
    "                base_estimator=BaggingClassifier(**gnb_params()),\n",
    "                **calibration_params(),\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"ridge\",\n",
    "            CalibratedClassifierCV(\n",
    "                base_estimator=RidgeClassifier(**ridge_params()), **calibration_params()\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    ").fit(data, y_true)\n",
    "\n",
    "voting_gnb_logreg = lambda: VotingClassifier(\n",
    "    estimators=[\n",
    "        (\n",
    "            \"gnb\",\n",
    "            CalibratedClassifierCV(\n",
    "                base_estimator=BaggingClassifier(**gnb_params()),\n",
    "                **calibration_params(),\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"logreg\",\n",
    "            CalibratedClassifierCV(\n",
    "                base_estimator=LogisticRegression(**logreg_params(logreg_C)),\n",
    "                **calibration_params(),\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    ").fit(data, y_true)\n",
    "\n",
    "voting_logreg_ridge = lambda: VotingClassifier(\n",
    "    estimators=[\n",
    "        (\n",
    "            \"logreg\",\n",
    "            CalibratedClassifierCV(\n",
    "                base_estimator=LogisticRegression(**logreg_params(logreg_C)),\n",
    "                **calibration_params(),\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"ridge\",\n",
    "            CalibratedClassifierCV(\n",
    "                base_estimator=RidgeClassifier(**ridge_params()), **calibration_params()\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    ").fit(data, y_true)\n",
    "\n",
    "voting_gnb_logreg_ridge = lambda: VotingClassifier(\n",
    "    estimators=[\n",
    "        (\n",
    "            \"gnb\",\n",
    "            CalibratedClassifierCV(\n",
    "                base_estimator=BaggingClassifier(**gnb_params()),\n",
    "                **calibration_params(),\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"logreg\",\n",
    "            CalibratedClassifierCV(\n",
    "                base_estimator=LogisticRegression(**logreg_params(logreg_C)),\n",
    "                **calibration_params(),\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"ridge\",\n",
    "            CalibratedClassifierCV(\n",
    "                base_estimator=RidgeClassifier(**ridge_params()), **calibration_params()\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    ").fit(data, y_true)\n",
    "\n",
    "stacked_pass = lambda: StackingClassifier(\n",
    "    estimators=[\n",
    "        (\n",
    "            \"ridge\",\n",
    "            RidgeClassifier(**ridge_params()),\n",
    "        ),\n",
    "        (\n",
    "            \"gnb\",\n",
    "            BaggingClassifier(**gnb_params()),\n",
    "        ),\n",
    "    ],\n",
    "    final_estimator=LogisticRegressionCV(\n",
    "        scoring=\"neg_log_loss\",\n",
    "        **logreg_params(None),\n",
    "    ),\n",
    "    cv=list(cross_validator()),\n",
    "    n_jobs=-1,\n",
    "    passthrough=True,\n",
    "    verbose=1,\n",
    ").fit(data, y_true)\n",
    "\n",
    "stacked = lambda: StackingClassifier(\n",
    "    estimators=[\n",
    "        (\n",
    "            \"ridge\",\n",
    "            RidgeClassifier(**ridge_params()),\n",
    "        ),\n",
    "        (\n",
    "            \"gnb\",\n",
    "            BaggingClassifier(**gnb_params()),\n",
    "        ),\n",
    "    ],\n",
    "    final_estimator=LogisticRegressionCV(\n",
    "        scoring=\"neg_log_loss\",\n",
    "        **logreg_params(None),\n",
    "    ),\n",
    "    cv=list(cross_validator()),\n",
    "    n_jobs=-1,\n",
    "    passthrough=False,\n",
    "    verbose=1,\n",
    ").fit(data, y_true)\n",
    "\n",
    "logreg = lambda: LogisticRegression(**logreg_params(logreg_C)).fit(data, y_true)\n",
    "\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.11 s\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"bagging_gnb\": bagging_gnb(),\n",
    "    \"ridge\": ridge(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "models[\"voting_gnb_logreg\"] = voting_gnb_logreg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "models[\"stacked\"] = stacked()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "models[\"stacked_pass\"] = stacked_pass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.45 s\n"
     ]
    }
   ],
   "source": [
    "models[\"logreg\"] = logreg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "models[\"voting_gnb_logreg_ridge\"] = voting_gnb_logreg_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12 s\n"
     ]
    }
   ],
   "source": [
    "models[\"voting_gnb_ridge\"] = voting_gnb_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "models[\"voting_logreg_ridge\"] = voting_logreg_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f44314378143b589e583b5acb26515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_gnb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/bagging_gnb.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/ridge.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_gnb_logreg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/voting_gnb_logreg.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacked\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/stacked.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacked_pass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/stacked_pass.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/logreg.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_gnb_logreg_ridge\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/voting_gnb_logreg_ridge.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_gnb_ridge\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/voting_gnb_ridge.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_logreg_ridge\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./prototypes/voting_logreg_ridge.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2 s\n"
     ]
    }
   ],
   "source": [
    "for model, estimator in tqdm(models.items()):\n",
    "    print(model)\n",
    "    dump(estimator, f\"{DATA_OUT_FOLDER}/prototypes/{model}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to try again on the holdout data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed since notebook_begin_time: 211.12521982192993 s\n",
      "time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time elapsed since notebook_begin_time: {time() - notebook_begin_time} s\")\n",
    "_ = gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1781be99c106060f3abc0c9b91d3d379f24672894e2158d4b74304109955878"
  },
  "kernelspec": {
   "display_name": "Python [conda env:capstone_pyspark_38] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
